---
title: "Selecting locations for Timed-swim surveys Post 2020"
author: "Jaime McAllister and Craig Mundy"
date: "`r Sys.Date()`"
output:
  pdf_document:
    fig_height: 8
    fig_width: 8
    includes:
      in_header: header.tex
    toc: yes
  word_document:
    fig_caption: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = "",     ## nothing goes in front of each line
                      message = FALSE,  ## into the console, not the document
                      warning = FALSE,  ## into the console, not the document
                      fig.align = "center",
                      fig.show = "hold",
                      out.height = "0.8\\textwidth",
                      out.width = "0.8\\textwidth")
options(knitr.kable.NA = '')


suppressPackageStartupMessages({
library(tictoc)
library(sf)
library(nngeo)
library(maptools)
library(rgdal)
library(sp)
library(spatialEco)  
library(rgeos)
library(lubridate)
library(spdplyr)
library(tidyverse)
library(tmap)
library(tictoc)
library(spdep)
library(openxlsx)  
})

## set EPSG CRS

GDA2020 <- st_crs(7855)
GDA94 <- st_crs(28355)
WGS84 <- st_crs(4326)

```
# Read in hex layer
Read in grid wide spatial layer, and transform to GDA2020. This hex cell layer contains the majority of fishing activity in the closed blocks.

```{r prepare base layers}
## Read in abalone wide hex layer
# ab.hex <- readRDS(sprintf("C:/Users/%s/University of Tasmania/IMAS-DiveFisheries - Assessments - Documents/Assessments/GIS/SpatialLayers/g1hawide_2020_03_24.rds", Sys.info()[["user"]]))

ab.hex <- readRDS(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/GIS/SpatialLayers/g1hawide_2020_03_24.rds", Sys.info()[["user"]])))

## convert to sf
sf.ab.hex <- st_as_sf(ab.hex)

## Transform from GDA94 to GDA2020
sf.ab.hex <- st_transform(sf.ab.hex, GDA2020)

```
# Add quartile to dataframe
THe input variable is the total catch in Kg for each cell from 2012 - 2019. We use the dplyr ntile() function to calculate five quantiles (0-20, 20-40, etc) based on total catch. Given that there is negligible fishing in 2018 and 2019, we could sum catch across 2012-2017 and use an variation if we think the 2018/2019 fishing events are sufficinetly unusual.

```{r add quartile var}
# Filter hex layer to required block and add quartile
ts.hex <- filter(sf.ab.hex, zone == 'E' &
                  blockno %in% c(16, 21, 22, 23, 24, 27, 28, 29)|
                  subblockno == '28A') %>%
  mutate(subblockno = gsub(" ", "", subblockno)) %>%
  within({
    cell.ntile <- ntile(blkgtotal, 5)
  })

# ts.hex <- filter(sf.ab.hex, zone == 'N' &
#                   blockno %in% c(5, 6)) %>%
#   mutate(subblockno = gsub(" ", "", subblockno)) %>%
#   within({
#     cell.ntile <- ntile(blkgtotal, 5)
#   })

# # Hex layer and quartile for entire state
# ts.hex <- sf.ab.hex %>%
#   mutate(subblockno = gsub(" ", "", subblockno)) %>%
#   within({
#     cell.ntile <- ntile(blkgtotal, 5)
#   })

# outname.ts.hex <- sprintf("C:/Users/%s/University of Tasmania/IMAS-DiveFisheries - Assessments - Documents/Assessments/GIS/SpatialLayers/TimedSwimSites_Hexcell_BL_quantiles.gpkg", Sys.info()[["user"]])

outname.ts.hex <- sprintf(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/GIS/SpatialLayers/TimedSwimSites_Hexcell_BL_quantiles.gpkg", Sys.info()[["user"]])))

# outname.ts.hex <- sprintf("C:/Users/%s/University of Tasmania/IMAS-DiveFisheries - Assessments - Documents/Assessments/GIS/SpatialLayers/Blacklip_Hexcell_quantiles.gpkg", Sys.info()[["user"]])

st_write(ts.hex, dsn = outname.ts.hex, layer = "pointqt", driver = "GPKG", append = F)

hex.cell.summary <- ts.hex %>%
  st_set_geometry(NULL) %>%
  group_by(cell.ntile) %>%
  summarise(
    mncatch = mean(blkgtotal, na.rm = T),
    catch = sum(blkgtotal, na.rm = T),
    n = n()
  ) %>%
  print()

```
# Reference Site Selection from 2020
Randomly select 15 sites from each block to keep as reference sites for 2021 survey and beyond.

```{r reference site selection 2021}

# Set seed
set.seed(123) 

# Randomly select 15 sites from 2020 data
sites.2020.keep <- time.swim.dat.final %>%
 filter(sampyear == 2020,
        !subblockno %in% c('28B', '28C')) %>% 
 group_by(blockno) %>% 
 distinct(site, .keep_all = T) %>% 
 sample_n(15) %>% 
 select(-proposed.geom) %>% 
 st_as_sf()

# save GIS spatial layer
# st_write(sites.2020.keep,
#          dsn = "C:/Users/jaimem/Documents/Abalone_research/AB_TimedSwimFIS/FIS_TIMEDSWIMSITES_2020REFERENCE_2021-05-17.gpkg", layer = "sites.2020.keep", driver = "GPKG", overwrite = T, delete_dsn = T)

# NOTE: set.seed wasn't used when generating the selection of reference sites from 2020 to use in 2021.
# Therefore the resulting output gpkg file above has been re-imported to identify those reference sites
# and stored as an RDS for future reference.

# sites.2020.kept.sf <- st_read('C:/CloudStor/R_Stuff/FIS/FIS_2021/FIS_TimedSwimSurveys2021/FIS_TIMEDSWIMSITES_2020REFERENCE_2021-05-17.gpkg')

# convert to data frame
sites.2020.kept.df <- sites.2020.kept.sf %>%
 sfheaders::sf_to_df(fill = T)

# save file
# saveRDS(sites.2020.kept.df, 'C:/CloudStor/Shared/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2021/time.swim.2020.repeat.sites.RDS')

```

# Post 2020 Site Selection
Timed swim surveys in subsequent years after the collection of baseline data in 2020 involve a semi-repeated measures experimental design where 15 sites from each block sampled in 2020 have been carried over as 'reference' sites with the remaining 45 sites randomly selected from the GPS logger data after excluding all previous GPS logger sites sampled in 2020 (n = 229). 
```{r post 2020 site selection}
## Post 2020 site selection ####

# Specify assessment year
assess_year <- 2024

# Import final timed swim dataframe from previous assessment year

time.swim.dat.final <- readRDS(file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata',
Sys.info()[["user"]])), paste('FIS_TimedSwimSurveys', assess_year - 1, sep = ''), 'time.swim.dat.final.RDS', sep = ''))                                  

# outname_point <- sprintf(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/GIS/SpatialLayers/TimedSwimSites_Block5-6_Final_2024.gpkg", Sys.info()[["user"]])))

# outname_point <- paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2021',
#                                 Sys.info()[["user"]]))

outname_point <- file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata',
Sys.info()[["user"]])), paste('FIS_TimedSwimSurveys', assess_year, sep = ''))

# Import reference sites
time_swim_ref_sites <- readRDS(file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata',
Sys.info()[["user"]])), paste('FIS_TimedSwimSurveys2021'), 'time.swim.2020.repeat.sites.RDS', sep = '')) 

time_swim_ref_sites <- time_swim_ref_sites %>% 
 mutate(ref_site = 'ref')

# Create vector of OIDs for reference sites to be sampled in assessment year 
# Note: 12 of the randomly selected reference sites are SAM historical research sites (i.e. n = 78) and
# have unallocated OIDs
ref_sites <- time_swim_ref_sites

ref_sites_oid <- ref_sites %>% 
        filter(!is.na(oid)) %>% 
        ungroup() %>% 
        pull(oid)

# Create vector of all OIDs sampled in previous assessment years to filter from
# current assessment year random site selection
ts_sites_sampled <- time.swim.dat.final %>%
        filter(!subblockno %in% c('28B', '28C')) %>% 
        group_by(blockno) %>% 
        distinct(site, .keep_all = T) %>% 
        filter(!is.na(oid)) %>% 
        ungroup() %>% 
        pull(oid)

# Create vector of blocks
blocknos <- c(16, 22, 23, 24, 27, 28)
# blocknos <- c(5, 6)

# Create empty lists to populate with random hex cells for each block 
ts_site_list <- list()

# Set seed
set.seed(1234)

# Run loops to generate random hex cells for each closed and reference block
for (i in blocknos){
cellqt <- ts.hex %>% 
  filter(!oid %in% ts_sites_sampled &
           cell.ntile > 2 &
           !subblockno %in% c('28B', '28C') &
           blockno == i) %>%  
  group_by(blockno, cell.ntile) %>%
  # as_Spatial() %>% 
  subsample.distance(size = 60, d = 300) %>% #change size = 45
  st_as_sf() %>% 
  ungroup()

ts_site_list[[i]] <- cellqt
}

# for (i in blocknos){
# cellqt <- ts.hex %>% 
#   filter(cell.ntile > 2 &
#            subblockno %in% c('29A', '29B') &
#            blockno == i) %>%  
#   group_by(blockno, cell.ntile) %>%
#   # as_Spatial() %>% 
#   subsample.distance(size = 60, d = 300) %>% #change size = 45
#   st_as_sf() %>% 
#   ungroup()
# 
# ts_site_list[[i]] <- cellqt
# }
# 
# for (i in blocknos){
# cellqt <- ts.hex %>% 
#   filter(cell.ntile > 2 &
#            blockno == i) %>%  
#   group_by(blockno, cell.ntile) %>%
#   # as_Spatial() %>% 
#   subsample.distance(size = 60, d = 300) %>% #change size = 45
#   st_as_sf() %>% 
#   ungroup()
# 
# ts_site_list[[i]] <- cellqt
# }


# Combine rows of each separate list to create single sf
ts_sites_sf <- bind_rows(ts_site_list)


# Find the centroid of each hex cell to create point/site location coordinates
ts_sites_pointqt_sf <- st_centroid(ts_sites_sf)

# Convert geometry to latitude and longitude to create dataframe
ts_sites_df <- ts_sites_pointqt_sf %>%
        st_transform(crs = st_crs(4326)) %>%
  sfheaders::sf_to_df(fill = T) %>%
  select(c(zone, blockno, subblockno, cell.ntile, oid, x, y)) %>%
  dplyr::rename('latitude' = y,
                'longitude' = x)

# Quick summary check of random sites generate per block
# Note: Block 28 had limited data to generate 45 sites.
ts_sites_df %>%
  group_by(blockno) %>%
  summarise(n = n())


# Add site names using naming convention 'AB-sampyear-blockno-site.order'
ts_sites_df <- ts_sites_df %>% 
 group_by(blockno) %>% 
  mutate(site_no = row_number(),
         site = paste('AB', assess_year, blockno, site_no, sep = '-')) %>% 
 ungroup()


# Quick plot to examine sites for chosen block
ts_sites_df %>% 
  filter(blockno == 5) %>%
ggplot(aes(x = longitude, y = latitude))+
  geom_point()+
  # geom_path(arrow = arrow(type = "closed", length = unit(0.05, "npc")), aes(longitude, latitude, color = angle))+
  geom_point(aes(x = max(longitude), y = median(latitude)), color = 'red')+
  geom_text(aes(label = site_no), size = 4, color = 'red')

# Unset seed
set.seed(NULL)

```

# Combine all new sites for assessment year with reference sites retained from 2020 in single dataframe

```{r rejoin ts sites}
# Create dataframe of reference sites
ts_ref_sites_df <- time_swim_ref_sites %>%
 st_as_sf(coords = c("x", "y")) %>% 
  st_set_crs(st_crs(7855)) %>%
  st_transform(crs = st_crs(4326)) %>%
  sfheaders::sf_to_df(fill = T) %>%
  select(site.new, blockno, subblockno, oid, cell.ntile, sam.count, x, y, ref_site) %>% 
  dplyr::rename('latitude' = y,
                'longitude' = x,
                'site' = site.new) %>% 
  mutate(blockno = as.integer(blockno),
         cell.ntile = as.integer(cell.ntile))

ts_sites_df <- ts_sites_df %>% 
  select(site, blockno, subblockno, oid, cell.ntile, longitude, latitude)

ts_sites_final_df <- bind_rows(ts_ref_sites_df, ts_sites_df) %>% 
 arrange(blockno) %>% 
 mutate(ref_site = ifelse(is.na(ref_site), 'new', ref_site))

# ts_sites_final_df <- ts_sites_df

ts_sites_final_sf  <-  ts_sites_final_df %>% 
  st_as_sf(coords = c('longitude', 'latitude'), crs = st_crs(4326))

ts_sites_final_gpx <- ts_sites_final_df %>% 
 dplyr::rename('name' = 'site') %>% 
 select(c(name, longitude, latitude)) %>% 
 add_column(description = NA, 
            comment = NA)

```
# Export data
```{r export data}

# Export folder path

gis_folder_path <- paste(file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/GIS/SpatialLayers/TimeSwimLayers',
Sys.info()[["user"]]), sep = '')))

data_folder_path <- paste(file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/', Sys.info()[["user"]]), paste('FIS_TimedSwimSurveys', assess_year, sep = ''), sep = '')))

# Export geospatial package for GIS and KML for Google Earth

outname_point <- paste(gis_folder_path, paste('/TimedSwimSites_EastCoast_Final_', assess_year, ".gpkg", sep = ""), sep = '')
outname_point <- paste(data_folder_path, paste('/TimedSwimSites_EastCoast_Final_', assess_year, ".gpkg", sep = ""), sep = '')

st_write(ts_sites_final_sf, dsn = outname_point, layer = "pointqt", driver = "GPKG", append = F)

# Export KML for Google Earth

outname_point_kml <- paste(gis_folder_path, paste('/TimedSwimSites_EastCoast_Final_', assess_year, ".kml", sep = ""), sep = '')
outname_point_kml <- paste(data_folder_path, paste('/TimedSwimSites_EastCoast_Final_', assess_year, ".kml", sep = ""), sep = '')

st_write(ts_sites_final_sf, dsn = outname_point_kml, layer = "pointqt", driver = "kml", append = F) 
 
# Export Excel files 
write.xlsx(ts_sites_final_df, paste(gis_folder_path, paste('/TimedSwimSites_EastCoast_Final_', assess_year, ".xlsx", sep = ""), sep = ''), sheetName = "Sheet1", colNames = TRUE, rowNames = TRUE, append = FALSE)
write.xlsx(ts_sites_final_df, paste(data_folder_path, paste('/TimedSwimSites_EastCoast_Final_', assess_year, ".xlsx", sep = ""), sep = ''), sheetName = "Sheet1", colNames = TRUE, rowNames = TRUE, append = FALSE)


# Export Excel file for GPX conversion
write.xlsx(ts_sites_final_gpx, paste(gis_folder_path, paste('/TimedSwimSites_EastCoast_Final_', assess_year, '_GPX', ".xlsx", sep = ""), sep = ''), sheetName = "Sheet1", colNames = TRUE, rowNames = TRUE, append = FALSE)
write.xlsx(ts_sites_final_gpx, paste(data_folder_path, paste('/TimedSwimSites_EastCoast_Final_', assess_year, '_GPX', ".xlsx", sep = ""), sep = ''), sheetName = "Sheet1", colNames = TRUE, rowNames = TRUE, append = FALSE)
  
```
