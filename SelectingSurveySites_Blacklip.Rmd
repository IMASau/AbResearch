---
title: "Selecting locations for Timed-swim surveys Post 2020"
author: "Jaime McAllister and Craig Mundy"
date: "`r Sys.Date()`"
output:
  pdf_document:
    fig_height: 8
    fig_width: 8
    includes:
      in_header: header.tex
    toc: yes
  word_document:
    fig_caption: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = "",     ## nothing goes in front of each line
                      message = FALSE,  ## into the console, not the document
                      warning = FALSE,  ## into the console, not the document
                      fig.align = "center",
                      fig.show = "hold",
                      out.height = "0.8\\textwidth",
                      out.width = "0.8\\textwidth")
options(knitr.kable.NA = '')


suppressPackageStartupMessages({
library(tictoc)
library(sf)
library(nngeo)
library(maptools)
library(rgdal)
library(sp)
library(spatialEco)  
library(rgeos)
library(lubridate)
library(spdplyr)
library(tidyverse)
library(tmap)
library(tictoc)
library(spdep)
library(openxlsx)  
})

## set EPSG CRS

GDA2020 <- st_crs(7855)
GDA94 <- st_crs(28355)
WGS84 <- st_crs(4326)

```
# Read in hex layer
Read in grid wide spatial layer, and transform to GDA2020. This hex cell layer contains the majority of fishing activity in the closed blocks.

```{r prepare base layers}
## Read in abalone wide hex layer
ab.hex <- readRDS(sprintf("C:/Users/%s/University of Tasmania/IMAS-DiveFisheries - Assessments - Documents/Assessments/GIS/SpatialLayers/g1hawide_2020_03_24.rds", Sys.info()[["user"]]))

## convert to sf
sf.ab.hex <- st_as_sf(ab.hex)

## Transform from GDA94 to GDA2020
sf.ab.hex <- st_transform(sf.ab.hex, GDA2020)

```
# Add quartile to dataframe
THe input variable is the total catch in Kg for each cell from 2012 - 2019. We use the dplyr ntile() function to calculate five quantiles (0-20, 20-40, etc) based on total catch. Given that there is negligible fishing in 2018 and 2019, we could sum catch across 2012-2017 and use an variation if we think the 2018/2019 fishing events are sufficinetly unusual.

```{r add quartile var}
# Filter hex layer to required block and add quartile
ts.hex <- filter(sf.ab.hex, zone == 'E' &
                  blockno %in% c(16, 22, 23, 24, 27, 28)|
                  subblockno == '28A') %>% 
  mutate(subblockno = gsub(" ", "", subblockno)) %>%
  within({
    cell.ntile <- ntile(blkgtotal, 5)
  })

outname.ts.hex <- sprintf("C:/Users/%s/University of Tasmania/IMAS-DiveFisheries - Assessments - Documents/Assessments/GIS/SpatialLayers/TimedSwimSites_Hexcell_BL_quantiles.gpkg", Sys.info()[["user"]])

st_write(ts.hex, dsn = outname.ts.hex, layer = "pointqt", driver = "GPKG", append = F)

hex.cell.summary <- ts.hex %>%
  st_set_geometry(NULL) %>%
  group_by(cell.ntile) %>%
  summarise(
    mncatch = mean(blkgtotal, na.rm = T),
    catch = sum(blkgtotal, na.rm = T),
    n = n()
  ) %>%
  print()

```
# Post 2020 Site Selection
Timed swim surveys in subsequent years after the collection of baseline data in 2020 involve a semi-repeated measures experimental design where 15 sites from each block sampled in 2020 have been carried over as 'reference' sites with the remaining 45 sites randomly selected from the GPS logger data after excluding all previous GPS logger sites sampled in 2020 (n = 229). 
```{r post 2020 site selection}
## Post 2020 site selection ####

# Specify assessment year
assess_year <- 2023

# Import final timed swim dataframe from previous assessment year
time.swim.dat.final <-
        readRDS(paste0('C:/CloudStor/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys', assess_year - 1, '/time.swim.dat.final.RDS'))

# Import reference sites
time_swim_ref_sites <- readRDS('C:/CloudStor/R_Stuff/FIS/FIS_2021/FIS_TimedSwimSurveys2021/time.swim.2020.repeat.sites.RDS')

# Create vector of OIDs for reference sites to be sampled in assessment year 
# Note: 12 of the randomly selected reference sites are SAM historical research sites (i.e. n = 78) and
# have unallocated OIDs
ref_sites <- time_swim_ref_sites
ref_sites_oid <- ref_sites %>% 
        filter(!is.na(oid)) %>% 
        ungroup() %>% 
        pull(oid)

# Create vector of all OIDs sampled in previous assessment years to filter from
# current assessment year random site selection
ts_sites_sampled <- time.swim.dat.final %>%
        filter(!subblockno %in% c('28B', '28C')) %>% 
        group_by(blockno) %>% 
        distinct(site, .keep_all = T) %>% 
        filter(!is.na(oid)) %>% 
        ungroup() %>% 
        pull(oid)

# Create vector of blocks
blocknos <- c(16, 22, 23, 24, 27, 28)

# Create empty lists to populate with random hex cells for each block 
ts_site_list <- list()

# Set seed
set.seed(1234)

# Run loops to generate random hex cells for each closed and reference block
for (i in blocknos){
cellqt <- ts.hex %>% 
  filter(!oid %in% ts_sites_sampled &
           cell.ntile > 2 &
           !subblockno %in% c('28B', '28C') &
           blockno == i) %>%  
  group_by(blockno, cell.ntile) %>%
  # as_Spatial() %>% 
  subsample.distance(size = 45, d = 300) %>% 
  st_as_sf() %>% 
  ungroup()

ts_site_list[[i]] <- cellqt
}


# Combine rows of each separate list to create single sf
ts_sites_sf <- bind_rows(ts_site_list)


# Find the centroid of each hex cell to create point/site location coordinates
ts_sites_pointqt_sf <- st_centroid(ts_sites_sf)

# Convert geometry to latitude and longitude to create dataframe
ts_sites_df <- ts_sites_pointqt_sf %>%
        st_transform(crs = st_crs(4326)) %>%
  sfheaders::sf_to_df(fill = T) %>%
  select(c(zone, blockno, subblockno, cell.ntile, oid, x, y)) %>%
  dplyr::rename('latitude' = y,
                'longitude' = x)

# Quick summary check of random sites generate per block
# Note: Block 28 had limited data to generate 45 sites.
ts_sites_df %>%
  group_by(blockno) %>%
  summarise(n = n())


# Add site names using naming convention 'AB-sampyear-blockno-site.order'
ts_sites_df <- ts_sites_df %>% 
 group_by(blockno) %>% 
  mutate(site_no = row_number(),
         site = paste('AB', assess_year, blockno, site_no, sep = '-')) %>% 
 ungroup()


# Quick plot to examine sites for chosen block
ts_sites_df %>% 
  filter(blockno == 16) %>%
ggplot(aes(x = longitude, y = latitude))+
  geom_point()+
  # geom_path(arrow = arrow(type = "closed", length = unit(0.05, "npc")), aes(longitude, latitude, color = angle))+
  geom_point(aes(x = max(longitude), y = median(latitude)), color = 'red')+
  geom_text(aes(label = site_no), size = 4, color = 'red')

# Unset seed
set.seed(NULL)

```

# Combine all new sites for assessment year with reference sites retained from 2020 in single dataframe

```{r rejoin ts sites}
# Create dataframe of reference sites
ts_ref_sites_df <- time_swim_ref_sites %>%
 st_as_sf(coords = c("x", "y")) %>% 
  st_set_crs(st_crs(7855)) %>%
  st_transform(crs = st_crs(4326)) %>%
  sfheaders::sf_to_df(fill = T) %>%
  select(site.new, blockno, subblockno, oid, cell.ntile, sam.count, x, y) %>% 
  dplyr::rename('latitude' = y,
                'longitude' = x,
                'site' = site.new) %>% 
  mutate(blockno = as.integer(blockno),
         cell.ntile = as.integer(cell.ntile))

ts_sites_df <- ts_sites_df %>% 
  select(site, blockno, subblockno, oid, cell.ntile, longitude, latitude)

ts_sites_final_df <- bind_rows(ts_ref_sites_df, ts_sites_df) %>% 
 arrange(blockno)

ts_sites_final_sf  <-  ts_sites_final_df %>% 
  st_as_sf(coords = c('longitude', 'latitude'), crs = st_crs(4326))

ts_sites_final_gpx <- ts_sites_final_df %>% 
 dplyr::rename('name' = 'site') %>% 
 select(c(name, longitude, latitude)) %>% 
 add_column(description = NA, 
            comment = NA)

```
# Export data
```{r export data}

# Export geospatial package for GIS and KML for Google Earth
outname_point <- sprintf(paste0("C:/Users/%s/University of Tasmania/IMAS-DiveFisheries - Assessments - Documents/Assessments/GIS/SpatialLayers/TimedSwimSites_EastCoast_Final_", assess_year, ".gpkg", sep = ""), Sys.info()[["user"]])

st_write(ts_sites_final_sf, dsn = outname_point, layer = "pointqt", driver = "GPKG", append = F)

# Export KML for Google Earth
outname_point_kml <- paste0('C:/CloudStor/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys', assess_year, '/TimedSwim_EastCoast/TimedSwimSites_EastCoast_Final', assess_year, ".kml", sep = "")
st_write(ts_sites_final_sf, dsn = outname_point_kml, layer = "pointqt", driver = "kml", append = F) 
 
# Export Excel files 
 write.xlsx(ts_sites_final_df, sprintf(paste0("C:/Users/%s/University of Tasmania/IMAS-DiveFisheries - Assessments - Documents/Assessments/GIS/SpatialLayers/TimedSwimSites_EastCoast_Final", assess_year, ".xlsx", sep = ""), Sys.info()[["user"]]), 
            sheetName = "Sheet1", 
            colNames = TRUE, rowNames = TRUE, append = FALSE)
 
write.xlsx(ts_sites_final_df, paste0('C:/CloudStor/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys', assess_year, '/TimedSwim_EastCoast/TimedSwimSites_EastCoast_Final', assess_year, ".xlsx", sep = ""), 
            sheetName = "Sheet1", 
            colNames = TRUE, rowNames = TRUE, append = FALSE)

# Export Excel file for GPX conversion
write.xlsx(ts_sites_final_gpx, paste0('C:/CloudStor/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys', assess_year, '/TimedSwim_EastCoast/TimedSwimSites_EastCoast_Final', assess_year, '_GPX', ".xlsx", sep = ""), 
            sheetName = "Sheet1", 
            colNames = TRUE, rowNames = FALSE, append = FALSE)


  
```
