---
title: "Blacklip Timed Swim Data Compile"
author:
  - name: Jaime McAllister
    affiliations:
        - name: IMAS, University of Tasmania
          department: IMAS-FA
date: last-modified
date-format: "[Last Updated on] DD MMMM, YYYY"
format:
  docx:
    highlight-style: github
    papersize: A4
    code-overflow: "wrap"
    reference-doc: word-styles-reference-01.docx
    toc: true
    number-sections: false
    toc-depth: 4
    number-depth: 4
    margin-left: 0.75in
    margin-right: 0.75in
    margin-top: 1in
    margin-bottom: 1in
  pdf:
    documentclass: scrreport
    keep-tex:  true
    dpi: 600
    pdf-engine: lualatex
    toc: true
    toc-depth: 4
    toc_float: true
    number-sections: false
    number-depth: 4
    highlight-style: github
    papersize: "A4paper"
    linestretch: 1.25
    mainfont: Calibri
    geometry:
      - left = 20mm
      - right = 20mm
      - top = 20mm
      - bottom = 10mm
editor: 
  markdown: 
    wrap: 72
---

```{r setup}
#| echo: false
#| warning: false
#| message: false

##---------------------------------------------------------------------------##
# Clear console
rm(list = ls())

##---------------------------------------------------------------------------##
## 1. Load libraries ####
suppressPackageStartupMessages({
        library(dplyr)
        library(ggplot2)
        library(scales)
        library(tidyr)
        library(gdata)
        library(openxlsx)
        library(lubridate)
        library(reshape)
        library(gridExtra)
        library(ggpubr)
        library(readxl)
        library(tibble)
        library(data.table)
        library(janitor)
        library(anytime)
        library(stringr)
        library(broom)
        library(purrr)
        library(sf)
        library(ggspatial)
        library(tmap)
        library(sf)
        library(sp)
        library(RColorBrewer)
        library(viridis)
        library(ggpmisc)
        library(arsenal)
  library(fuzzyjoin)
 library(tidytext)
})

source("C:/GitCode/AbResearch/getLegend.r")
source("C:/GitCode/AbResearch/StandardError_Functions.r")

##---------------------------------------------------------------------------##
## 2. Set sample year and file paths ####

# Identify sampling year of interest
samp_year <- 2024

# Identify folder containing sampling year site data
samp_year_folder <- file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata', 
                                            Sys.info()[["user"]])), paste('FIS_TimedSwimSurveys', samp_year, sep = ''))

# Identify sampling year folder to save any figure outputs 
ts_plots_folder <- file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/Assessment/Figures/FIS', 
                                           Sys.info()[["user"]])), paste('FIS_TimedSwimSurveys', samp_year, '_Plots', sep = ''))
##---------------------------------------------------------------------------##

```

```{r rawdata}
#| echo: false
#| warning: false
#| message: false

##---------------------------------------------------------------------------##
## 3. Load raw data ####

# Load timed swim measuring slate raw data
time.swim.dat <- read.xlsx("R:/TAFI/TAFI_MRL_Sections/Abalone/Section Shared/Abalone_databases/Data/Data for Transfer/2020/FIS_TimedSwim_RawData_2020.xlsx",
                       detectDates = T)

# Load timed swim vessel meta data
time.swim.meta.dat <- read.xlsx("R:/TAFI/TAFI_MRL_Sections/Abalone/Section Shared/Abalone_databases/Data/Data for Transfer/2020/FIS_TimedSwim_MetaData_2020.xlsx",
                           detectDates = T)
##---------------------------------------------------------------------------##
## 4. Clean Excel blank and white space ####

# Remove blank or additional rows from raw data where cells have been pre-filled
# for data entry.This step can be deleted once data entry is complete.
time.swim.dat <- time.swim.dat %>% 
        filter(!is.na(starttime) &
                       !is.na(finishtime) &
                       !is.na(sizeclass_freq))

# Clean site data by removing white space from Excel data entry
time.swim.dat <- time.swim.dat %>% 
        mutate(site = str_trim(site))

time.swim.meta.dat <- time.swim.meta.dat %>% 
        mutate(site = str_trim(site))
##---------------------------------------------------------------------------##

```

```{r formatdata}
#| echo: false
#| warning: false
#| message: false

##---------------------------------------------------------------------------##
## 5. Re-format data ####

# Re-format Excel times for measuring slate data (time.swim.dat)
time.swim.dat$starttime <- convertToDateTime(time.swim.dat$starttime, origin = "1970-01-01", tz = "Australia/HOBART")
time.swim.dat$firstabtime <- convertToDateTime(time.swim.dat$firstabtime, origin = "1970-01-01", tz = "Australia/HOBART")
time.swim.dat$finishtime <- convertToDateTime(time.swim.dat$finishtime, origin = "1970-01-01", tz = "Australia/HOBART")

time.swim.dat <- time.swim.dat %>% 
        mutate(starttime = strftime(starttime, format="%H:%M:%S"),
               firstabtime = strftime(firstabtime, format="%H:%M:%S"),
               finishtime = strftime(finishtime, format="%H:%M:%S"))

time.swim.dat$starttime <- as.POSIXct(paste(time.swim.dat$sampdate, time.swim.dat$starttime), format = "%Y-%m-%d %H:%M:%S")
time.swim.dat$firstabtime <- as.POSIXct(paste(time.swim.dat$sampdate, time.swim.dat$firstabtime), format = "%Y-%m-%d %H:%M:%S")
time.swim.dat$finishtime <- as.POSIXct(paste(time.swim.dat$sampdate, time.swim.dat$finishtime), format = "%Y-%m-%d %H:%M:%S")

# Re-format Excel times for vessel meta-data (time.swim.meta.dat)
time.swim.meta.dat$time.in <- convertToDateTime(time.swim.meta.dat$time.in, origin = "1970-01-01", tz = "Australia/HOBART")
time.swim.meta.dat$time.out <- convertToDateTime(time.swim.meta.dat$time.out, origin = "1970-01-01", tz = "Australia/HOBART")

time.swim.meta.dat <- time.swim.meta.dat %>% 
        mutate(time.in = strftime(time.in, format="%H:%M:%S"),
               time.out = strftime(time.out, format="%H:%M:%S"))

time.swim.meta.dat$time.in <- as.POSIXct(paste(time.swim.meta.dat$date, time.swim.meta.dat$time.in), format = "%Y-%m-%d %H:%M:%S")
time.swim.meta.dat$time.out <- as.POSIXct(paste(time.swim.meta.dat$date, time.swim.meta.dat$time.out), format = "%Y-%m-%d %H:%M:%S")

# Rename column names and rename two additional sites surveyed in 2020 baseline
time.swim.meta.dat <- time.swim.meta.dat %>% 
        dplyr::rename('sampdate' = date,
                      'starttime' = time.in,
                      'finishtime' = time.out) %>% 
        mutate(site = gsub('AB-22-Random1', 'WP-72-73', site),
               site = gsub('AB-22-Random2', 'WP-74-75', site))

# Manually add vessel name to metadata for 2021-10-08 when RV Taroona was used
time.swim.meta.dat <- time.swim.meta.dat %>% 
  mutate(vesselname = ifelse(sampdate == as.Date('2021-10-08'), 'Taroona', 'MoranaII'))

```

```{r dataadditions}
#| echo: false
#| warning: false
#| message: false

##---------------------------------------------------------------------------##
## 6. Classification and calculation of addition data columns ####

# Extract blockno from site name and add blockno to additional research sites surveyed
# in 2020 that had a different naming convention to GPS logger sites.
time.swim.dat <- time.swim.dat %>% 
        mutate(nums = str_count(site, '\\d+')) %>% 
        # mutate(site2 = site) %>% 
        mutate(site2 = ifelse(nums == 2, site, '')) %>% 
        separate(col = site2, into = c('ab', 'blockno'), sep = '-') %>% 
        mutate(site3 = ifelse(nums == 3, site, '')) %>% 
        separate(col = site3, into = c('ab', 'sampyear2', 'blockno2'), sep = '-') %>%
        mutate(blockno = ifelse(blockno %in% c(72, 74, 'LEG', 'THU'), 22, 
                                ifelse(blockno %in% c('BRS'), 13, blockno))) %>% 
        mutate(blockno = ifelse(is.na(blockno), blockno2, blockno)) %>% 
        dplyr::select(-c(ab, sampyear2, blockno2, nums))

# Calculate elapsed dive time (seconds)
time.swim.dat <- time.swim.dat %>% 
        mutate(time.elapsed = ifelse(is.na(firstabtime), finishtime - starttime, finishtime - firstabtime))

# Add survey sampling year
time.swim.dat <- time.swim.dat %>% 
        mutate(sampyear = year(sampdate))

# Determine legal and sub-legal abalone
time.swim.dat <- time.swim.dat %>% 
        mutate(legal.size = ifelse(sizeclass %in% c("0-60", "60-100", "0-100", "0-20", "20-40", "40-60", "60-80", "80-100", "100-120", "120-140"), '<140 mm', '>140 mm'))

# Add mid-point to 2020 size classes; add 2021 size classes and add midpoint
time.swim.dat <- time.swim.dat %>% 
        separate(sizeclass, into = c('minsize', 'maxsize'), sep = '-', convert = TRUE, remove = F) %>% 
        mutate(midsize = (minsize + maxsize)/2,
               sizeclass.2021 = ifelse(maxsize <= 100, '0-100', sizeclass),
               midsize.2021 = ifelse(maxsize <= 100, 50, midsize))

# Create data frame of individual abalone lengths for length frequency analysis
time.swim.dat.df <- time.swim.dat %>% 
        uncount(sizeclass_freq, .remove = F) %>% 
        dplyr::rename('shelllength' = midsize,
                      'shelllength.2021' = midsize.2021)

```

```{r datacheck}
#| echo: false
#| warning: false
#| message: false

##---------------------------------------------------------------------------##
## 7. Check measuring slate raw data and vessel meta data frames match  ####

# Create summary data frame of measuring slate raw data sites sampled by date
ts.dat.sites <- time.swim.dat %>% 
        dplyr::select(sampdate, site) %>% 
        distinct_all()

# Create summary data frame of vessel metadata sampled by date 

# Note: sites have been removed.
# AB-22-4-A was on sand and survey abandoned in 2020 baseline.
# Betsey was a random site surveyed in 2020 baseline. 
# AB-2023-13-20 and AB-2023-13-109 measuring slate data sheets missing from dates. 

ts.meta.dat.sites <- time.swim.meta.dat %>% 
        dplyr::select(sampdate, site) %>%
 filter(!site %in% c('AB-22-4-A', 'Betsey'),
         (site != 'AB-2023-13-20' | sampdate != as.Date('2024-02-13')),
         (site != 'AB-2023-13-109' | sampdate != as.Date('2024-02-16'))) %>% 
        distinct_all()

# Compare data frames to see if the site-date combinations match
summary(arsenal::comparedf(ts.dat.sites, ts.meta.dat.sites, by = c('sampdate', 'site')))

```
```{r savedata}
#| echo: false
#| warning: false
#| message: false

# Save dataframes
saveRDS(time.swim.dat, paste(samp_year_folder, '/time.swim.dat.RDS', sep = ''))
saveRDS(time.swim.dat.df, paste(samp_year_folder, '/time.swim.dat.df.RDS', sep = ''))
saveRDS(time.swim.meta.dat, paste(samp_year_folder, '/time.swim.meta.dat.RDS', sep = ''))

```

```{r vesseldata}
#| echo: false
#| warning: false
#| message: false

##---------------------------------------------------------------------------##
## 8. Vessel GPS data compile ####

# Load data from vessel GPS downloads and match to raw data

# Identify folder containing GPX download files from vessel plotter
gps_downloads_folder <- paste(sprintf("C:/Users/%s/OneDrive - University of Tasmania/IMAS-DiveFisheries-FIS-Data/FIS_VesselGPS_Downloads", Sys.info()[["user"]]))

# Define CRS
GDA2020 <- st_crs(7855)
##---------------------------------------------------------------------------##
# Vessel data for 2020 surveys
morana.gps.2020 <- st_read(file.path(gps_downloads_folder, 'MORANAII-2020-10-09_download.gpx'), layer = 'waypoints')
##---------------------------------------------------------------------------##
# Vessel data for 2021 surveys
morana.gps.2021.a <- st_read(file.path(gps_downloads_folder, 'MORANAII-2021-07-15_download.gpx'), layer = 'waypoints')
morana.gps.2021.b <- st_read(file.path(gps_downloads_folder, 'MORANAII-2021-08-12_download.gpx'), layer = 'waypoints')
morana.gps.2021.c <- st_read(file.path(gps_downloads_folder, 'MORANAII-2021-09-08_download.gpx'), layer = 'waypoints')
morana.gps.2021.d <- st_read(file.path(gps_downloads_folder, 'MORANAII-2021-10-07_download.gpx'), layer = 'waypoints')
taroona.gps.2021.a <- st_read(file.path(gps_downloads_folder, 'TAROONA-2021-10-15_download.gpx'), layer = 'waypoints')

# vessel data for 2021 additional surveys (i.e. block 13-14)
morana.gps.ref <- st_read(file.path(gps_downloads_folder, 'MORANAII-2021-04-06_download.gpx'), layer = 'waypoints')

morana.gps.2021 <- bind_rows(morana.gps.2021.a, morana.gps.2021.b, morana.gps.2021.c, 
                             morana.gps.2021.d) %>% 
 distinct(., name, .keep_all = T)
##---------------------------------------------------------------------------##
# Vessel data for 2022 surveys
morana.gps.2022.a <- st_read(file.path(gps_downloads_folder, 'MORANAII-2022-08-10_download.gpx'), layer = 'waypoints')
morana.gps.2022.b <- st_read(file.path(gps_downloads_folder, 'MORANAII-2022-09-06_download.gpx'), layer = 'waypoints')
morana.gps.2022.c <- st_read(file.path(gps_downloads_folder, 'MORANAII-2022-09-27_download.gpx'), layer = 'waypoints')

morana.gps.2022 <- bind_rows(morana.gps.2022.a, morana.gps.2022.b, morana.gps.2022.c) %>% 
 distinct(., name, .keep_all = T)
##---------------------------------------------------------------------------##
# Vessel data for 2023 surveys
morana_gps_2023_a <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-03-27_download.gpx'), layer = 'waypoints')
morana_gps_2023_b <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-06-24_download.gpx'), layer = 'waypoints')
morana_gps_2023_c <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-07-17_download.gpx'), layer = 'waypoints')
morana_gps_2023_d <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-07-19_download.gpx'), layer = 'waypoints')
morana_gps_2023_e <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-08-03_download.gpx'), layer = 'waypoints')
morana_gps_2023_f <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-08-15_download.gpx'), layer = 'waypoints')
morana_gps_2023_g <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-08-30_download.gpx'), layer = 'waypoints')
morana_gps_2023_h <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-09-07_download.gpx'), layer = 'waypoints')
morana_gps_2023_i <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-09-19_download.gpx'), layer = 'waypoints')
morana_gps_2023_j <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-09-25_download.gpx'), layer = 'waypoints')
morana_gps_2023_k <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-10-02_download.gpx'), layer = 'waypoints')
morana_gps_2023_l <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-10-19_download.gpx'), layer = 'waypoints')
morana_gps_2023_m <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-10-31_download.gpx'), layer = 'waypoints') 
morana_gps_2023_n <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-11-21_download.gpx'), layer = 'waypoints') 
morana_gps_2023_o <- st_read(file.path(gps_downloads_folder, 'MORANAII-2023-11-30_download.gpx'), layer = 'waypoints') %>% 
 filter(time >= ymd_hms('2023-09-20 00:00:00'))

morana_gps_2023 <- bind_rows(morana_gps_2023_a, 
                             morana_gps_2023_b, 
                             morana_gps_2023_c, 
                             morana_gps_2023_d,
                             morana_gps_2023_e,
                             morana_gps_2023_f,
                             morana_gps_2023_g,
                             morana_gps_2023_h,
                             morana_gps_2023_i,
                             morana_gps_2023_j,
                             morana_gps_2023_k,
                             morana_gps_2023_l,
                             morana_gps_2023_m,
                             morana_gps_2023_n,
                             morana_gps_2023_o) %>% 
 mutate(gps_date = as.Date(time)) %>% 
 distinct(., name, gps_date, .keep_all = T)
##---------------------------------------------------------------------------##
# Vessel data for 2024 surveys
morana_gps_2024_a <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-02-07_download.gpx'), layer = 'waypoints')
morana_gps_2024_b <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-03-07_download.gpx'), layer = 'waypoints')
morana_gps_2024_c <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-03-21_download.gpx'), layer = 'waypoints')
morana_gps_2024_d <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-07-30_download.gpx'), layer = 'waypoints')
morana_gps_2024_e <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-08-08_download.gpx'), layer = 'waypoints')
morana_gps_2024_f <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-08-24_download.gpx'), layer = 'waypoints')
morana_gps_2024_g <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-09-10_download.gpx'), layer = 'waypoints')
morana_gps_2024_h <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-09-14_download.gpx'), layer = 'waypoints')
morana_gps_2024_i <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-09-27_download.gpx'), layer = 'waypoints')
morana_gps_2024_j <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-10-03_download.gpx'), layer = 'waypoints')
morana_gps_2024_k <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-10-10_download.gpx'), layer = 'waypoints')
morana_gps_2024_l <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-10-21_download.gpx'), layer = 'waypoints')
morana_gps_2024_m <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-10-23_download.gpx'), layer = 'waypoints')
morana_gps_2024_n <- st_read(file.path(gps_downloads_folder, 'MORANAII-2024-10-31_download.gpx'), layer = 'waypoints')

morana_gps_2024 <- bind_rows(morana_gps_2024_a, 
                             morana_gps_2024_b, 
                             morana_gps_2024_c,
                             morana_gps_2024_d,
                             morana_gps_2024_e,
                             morana_gps_2024_f,
                             morana_gps_2024_g,
                             morana_gps_2024_h,
                             morana_gps_2024_i,
                             morana_gps_2024_j,
                             morana_gps_2024_k,
                             morana_gps_2024_l,
                             morana_gps_2024_m,
                             morana_gps_2024_n) %>% 
 mutate(gps_date = as.Date(time)) %>% 
 distinct(., name, gps_date, .keep_all = T)

##---------------------------------------------------------------------------##
# Add sample year and vessel name to GPS data

# Note: gps time refers to time waypoint was uploaded or taken,
# therefore DO NOT use this column to determine year. Waypoint numbers should 
# always correspond to the actual sample time whereas names will generally 
# correspond to an upload time unless they have been manually entered)

morana.gps.2020 <- morana.gps.2020 %>%
        mutate(sampyear = 2020,
               vesselname = 'MoranaII')

morana.gps.ref <- morana.gps.ref %>%
        mutate(sampyear = 2021,
               vesselname = 'MoranaII')

morana.gps.2021 <- morana.gps.2021 %>%
        mutate(sampyear = 2021,
               vesselname = 'MoranaII')

taroona.gps.2021 <- taroona.gps.2021.a %>%
  distinct(., name, .keep_all = T) %>% 
  mutate(sampyear = 2021,
         vesselname = 'Taroona',
         name = as.numeric(name),
         name = if_else(name < 10, as.character(paste('00', name, sep = '')),
                                   if_else(between(name, 10, 99), as.character(paste(0, name, sep = '')),
                                           as.character(name))))
morana.gps.2022 <- morana.gps.2022 %>%
 mutate(sampyear = 2022,
        vesselname = 'MoranaII')

morana_gps_2023 <- morana_gps_2023 %>%
 mutate(sampyear = 2023,
        vesselname = 'MoranaII')

morana_gps_2024 <- morana_gps_2024 %>%
 mutate(sampyear = 2024,
        vesselname = 'MoranaII')
##---------------------------------------------------------------------------##
# Combine GPS dataframes

vessel.gps <- bind_rows(morana.gps.2020, morana.gps.ref, morana.gps.2021, taroona.gps.2021,
                        morana.gps.2022, morana_gps_2023, morana_gps_2024) %>%  
        mutate(gpsdate = as.Date(time),
               gpstime = time) %>% 
        dplyr::select(c(name, sampyear, gpstime, gpsdate, geometry, vesselname))
##---------------------------------------------------------------------------##
# Join GPS data with vessel metadata

# Load latest compiled RDS vessel meta-dataframe
time.swim.meta.dat <- readRDS(paste(samp_year_folder, '/time.swim.meta.dat.RDS', sep = ''))

# Separate start positions
ts.site.start <- time.swim.meta.dat %>%
        dplyr::select(-c(waypoint.finish, finishtime)) %>% 
        dplyr::rename('waypoint' = waypoint.start,
                      'samptime' = starttime) %>% 
        mutate(sampperiod = 'start',
               sampyear = year(sampdate))

# Separate finish positions
ts.site.finish <- time.swim.meta.dat %>%
        dplyr::select(-c(waypoint.start, starttime)) %>% 
        dplyr::rename('waypoint' = waypoint.finish,
                      'samptime' = finishtime) %>% 
        mutate(sampperiod = 'finish',
               sampyear = year(sampdate))

# Re-join start and finish positions and remove non-sampled sites (e.g. Betsey)        
ts.site.start.finish <- bind_rows(ts.site.start, ts.site.finish) %>%
        mutate(waypoint = if_else(waypoint < 10, as.character(paste('00', waypoint, sep = '')),
                                  if_else(between(waypoint, 10, 99), as.character(paste(0, waypoint, sep = '')),
                                          as.character(waypoint)))) %>%  
        dplyr::select(c(sampdate, samptime, sampperiod, site, waypoint, sampyear, vesselname)) %>%
filter(!site %in% c('AB-22-4-A', 'Betsey'),
         (site != 'AB-2023-13-20' | sampdate != as.Date('2024-02-13')),
         (site != 'AB-2023-13-109' | sampdate != as.Date('2024-02-16')))

# Join geometry where start waypoint recorded as being on the original GPS position/waypoint mark
# i.e. a new start gps waypoint not taken and survey began on proposed start waypoint
ts.site.start.finish.mark <- ts.site.start.finish %>% 
        filter(is.na(waypoint) & sampperiod == 'start') %>%  
        left_join(., vessel.gps, by = c('site' = 'name', 'sampyear', 'vesselname')) %>% 
        dplyr::select(c(sampyear, samptime, gpstime, sampperiod, site, waypoint, geometry, vesselname))

# Join geometry where start and finish waypoints were recorded 
ts.site.start.finish.wp <- ts.site.start.finish %>% 
        filter(!is.na(waypoint)) %>% 
        left_join(., vessel.gps, by = c('waypoint' = 'name', 'sampdate' = 'gpsdate', 'vesselname')) %>% 
        dplyr::rename('sampyear' = sampyear.x) %>%
        dplyr::select(c(sampyear, samptime, gpstime, sampperiod, site, waypoint, geometry, vesselname))

# re-join all waypoint data and transform to GDA2020
ts.site.start.finish.loc <- bind_rows(ts.site.start.finish.mark, ts.site.start.finish.wp) %>% 
        st_as_sf() %>% 
        st_transform(GDA2020)

vessel.gps.dat <- ts.site.start.finish.loc
##---------------------------------------------------------------------------##
# Re-combine metadata frame
ts_meta_dat <- bind_rows(ts.site.start, ts.site.finish) %>%
 mutate(waypoint = if_else(waypoint < 10, as.character(paste('00', waypoint, sep = '')),
                           if_else(between(waypoint, 10, 99), as.character(paste(0, waypoint, sep = '')),
                                   as.character(waypoint)))) %>%  
 dplyr::select(c(sampdate, samptime, sampperiod, site, waypoint, sampyear, vesselname, max.depth,
          habitat.type, percent.algae.cover, percent.urchins, urchin.deep, comments)) %>%
 filter(!site %in% c('AB-22-4-A', 'Betsey'),
         (site != 'AB-2023-13-20' | sampdate != as.Date('2024-02-13')),
         (site != 'AB-2023-13-109' | sampdate != as.Date('2024-02-16')))

# Separate metadata where start waypoint not recorded and join vessel gps data
meta_dat_no_wp <- ts_meta_dat %>% 
 filter(is.na(waypoint) & sampperiod == 'start') %>%  
 left_join(., vessel.gps, by = c('site' = 'name', 'sampyear', 'vesselname')) %>% 
 dplyr::select(c(sampyear, samptime, gpstime, sampperiod, site, waypoint, geometry, vesselname, max.depth,
          habitat.type, percent.algae.cover, percent.urchins, urchin.deep, comments))

# Separate metadata where start waypoint recorded and join vessel data
meta_dat_wp <- ts_meta_dat %>% 
 filter(!is.na(waypoint)) %>% 
 left_join(., vessel.gps, by = c('waypoint' = 'name', 'sampdate' = 'gpsdate', 'vesselname')) %>% 
 dplyr::rename('sampyear' = sampyear.x) %>%
 dplyr::select(c(sampyear, samptime, gpstime, sampperiod, site, waypoint, geometry, vesselname, max.depth,
          habitat.type, percent.algae.cover, percent.urchins, urchin.deep, comments))

# Recombine metadata and transform geometry
meta_dat_gps <- bind_rows(meta_dat_no_wp, meta_dat_wp) %>% 
 st_as_sf() %>% 
 st_transform(GDA2020)

# Extract blockno from site name
meta_dat_vessel <- meta_dat_gps %>% 
 mutate(nums = str_count(site, '\\d+')) %>% 
 mutate(site2 = ifelse(nums == 2, site, '')) %>% 
 separate(col = site2, into = c('ab', 'blockno'), sep = '-') %>% 
 mutate(site3 = ifelse(nums == 3, site, '')) %>% 
 separate(col = site3, into = c('ab', 'sampyear2', 'blockno2'), sep = '-') %>%
 mutate(blockno = ifelse(blockno %in% c(72, 74, 'LEG', 'THU'), 22, 
                         ifelse(blockno %in% c('BRS'), 13, blockno))) %>% 
 mutate(blockno = ifelse(is.na(blockno), blockno2, blockno)) %>% 
 dplyr::select(-c(ab, sampyear2, blockno2, nums)) %>% 
 relocate(blockno, .after = site)
##---------------------------------------------------------------------------##
# save files
saveRDS(vessel.gps.dat, paste(samp_year_folder, '/vessel.gps.dat.RDS', sep = ''))

saveRDS(meta_dat_vessel, paste(samp_year_folder, '/meta_dat_vessel.RDS', sep = ''))

# save spatial layer for QGIS
st_write(vessel.gps.dat,
         dsn = paste(samp_year_folder, '/vessel.gps.dat_', Sys.Date(), '.gpkg', sep = ''),
         layer = "vessel.gps.dat", driver = "GPKG", overwrite = T, delete_dsn = T)


rm(list = setdiff(ls(), c('vessel.gps.dat', 'meta_dat_vessel', 'time.swim.dat.df', 
                          'time.swim.meta.dat', 'time.swim.dat', 'samp_year', 'samp_year_folder',
                          'ts_meta_dat', 'ts.site.start.finish.loc')))

```


```{r proposedsites}
#| echo: false
#| warning: false
#| message: false

##---------------------------------------------------------------------------##
## 10. Proposed site data ####

# Identify sites sampled based on proposed GPS site data and
# create map of sites sampled within each Block adding subblock to site name 
# based on proposed position
# Use these data for 'proposed geometry' when joining to raw data 

# Combine proposed timed swim sites from all years into one data frame 

# Load final proposed sites for 2020 and 2021 surveys (i.e. adjusted site names)
# ts.sites.final.pre2022 <- readRDS(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2021/ts.sites.final.sf.RDS", Sys.info()[["user"]])))
##---------------------------------------------------------------------------##
# Load final proposed sites for 2020
ts_sites_final_2020 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2020/TimedSwimSites_EastCoast_Final_2020.xlsx", Sys.info()[["user"]]))) %>% .[,-1]
##---------------------------------------------------------------------------##
# Load final proposed sites for 2021
ts_sites_final_2021 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2021/TimedSwimSites_EastCoast_Final_2021.xlsx", Sys.info()[["user"]]))) %>% .[,-1]
##---------------------------------------------------------------------------##
# Load final proposed sites for 2022
ts_sites_final_2022 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2022/TimedSwimSites_EastCoast_Final_2022.xlsx", Sys.info()[["user"]]))) %>% .[,-1]
##---------------------------------------------------------------------------##
# Load final proposed sites for 2023
ts_sites_east_final_2023 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2023/TimedSwim_EastCoast/TimedSwimSites_EastCoast_Final_2023.xlsx", Sys.info()[["user"]]))) %>% .[,-1] %>% 
 mutate(blockno = as.numeric(blockno))

ts_sites_actaeons_final_2023 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2023/TimedSwim_Actaeons/TimedSwimSites_SubBlock13DE_Final_2023.xlsx", Sys.info()[["user"]]))) %>% .[,-1]

ts_sites_greens_final_2023 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2023/TimedSwim_NEGreens/TimedSwim_NE_GL_2023_50m.xlsx", Sys.info()[["user"]]))) %>% .[,-1] %>% mutate(oid = as.character(oid))

# ts_sites_block21_final_2023 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/GIS/SpatialLayers/TimeSwimLayers/TimedSwimSites_Block21_Final2023.xlsx", Sys.info()[["user"]]))) %>% .[,-1]

ts_sites_block21_final_2023 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2023/TimedSwimSites_Block21_Final_2023.xlsx", Sys.info()[["user"]]))) %>% .[,-1]

ts_sites_final_2023 <- bind_rows(ts_sites_east_final_2023, 
                                 ts_sites_actaeons_final_2023, 
                                 ts_sites_greens_final_2023,
                                 ts_sites_block21_final_2023)
##---------------------------------------------------------------------------##
# load final proposed sites for 2024
ts_sites_block29_final_2024 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2024/TimedSwimSites_Block29_Final2024_GPX.xlsx", Sys.info()[["user"]]))) %>% 
 dplyr::rename('site' = 'name')

ts_sites_east_final_2024 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2024/TimedSwimSites_EastCoast_Final_2024.xlsx", Sys.info()[["user"]]))) %>% .[,-1]

ts_sites_actaeons_final_2024 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2023/TimedSwim_Actaeons/TimedSwimSites_SubBlock13DE_Final_2023.xlsx", Sys.info()[["user"]]))) %>% .[,-1]

# ts_sites_block21_final_2024 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/GIS/SpatialLayers/TimeSwimLayers/TimedSwimSites_Block21_Final_2023.xlsx", Sys.info()[["user"]]))) %>% .[,-1]

ts_sites_block21_final_2024 <- read.xlsx(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata/FIS_TimedSwimSurveys2023/TimedSwimSites_Block21_Final_2023.xlsx", Sys.info()[["user"]]))) %>% .[,-1]

ts_sites_final_2024 <- bind_rows(ts_sites_block29_final_2024, 
                                 ts_sites_east_final_2024, 
                                 ts_sites_actaeons_final_2024,
                                 ts_sites_block21_final_2024)
##---------------------------------------------------------------------------##
# set CRS
GDA2020 <- st_crs(7855)
GDA94 <- st_crs(28355)
WGS84 <- st_crs(4326)

# convert 2020 site data to sf
ts.site.2020.sf <- ts_sites_final_2020 %>% 
 st_as_sf(coords = c("longitude", "latitude"), crs = WGS84) %>%
 dplyr::select(c(site, site_old, geometry, oid)) %>% 
 mutate(sampyear = 2020)

# convert 2021 site data to sf
ts.site.2021.sf <- ts_sites_final_2021 %>% 
 st_as_sf(coords = c("longitude", "latitude"), crs = WGS84) %>%
 dplyr::select(c(site, geometry, oid)) %>% 
 mutate(sampyear = 2021)

# convert 2022 site data to sf
ts.site.2022.sf <- ts_sites_final_2022 %>% 
 st_as_sf(coords = c("longitude", "latitude"), crs = WGS84) %>%
 dplyr::select(c(site, geometry, oid)) %>% 
 mutate(sampyear = 2022)

# convert 2023 site data to sf
ts.site.2023.sf <- ts_sites_final_2023 %>% 
 st_as_sf(coords = c("longitude", "latitude"), crs = WGS84) %>%
 dplyr::select(c(site, geometry, oid)) %>% 
 mutate(sampyear = 2023)

# convert 2024 site data to sf
ts.site.2024.sf <- ts_sites_final_2024 %>% 
 st_as_sf(coords = c("longitude", "latitude"), crs = WGS84) %>%
 # dplyr::rename('site' = 'name') %>% 
 dplyr::select(c(site, geometry, oid)) %>% 
 mutate(sampyear = 2024)

# ts.sites.final.pre2022 <- st_transform(ts.sites.final.pre2022, crs = WGS84)
##---------------------------------------------------------------------------##
# Combine all years
ts.sites.final.sf <- bind_rows(ts.site.2020.sf, ts.site.2021.sf, ts.site.2022.sf, ts.site.2023.sf, ts.site.2024.sf)
##---------------------------------------------------------------------------##
# save final proposed sites up to sample year
saveRDS(ts.sites.final.sf, paste(samp_year_folder, '/ts.sites.final.sf.RDS', sep = ''))

# save spatial layer for QGIS
st_write(ts.sites.final.sf, 
         dsn = paste(samp_year_folder, '/ts.sites.final.sf_', Sys.Date(), '.gpkg', sep = ''),
         layer = "ts.sites.final.sf", driver = "GPKG", overwrite = T, delete_dsn = T)

rm(list = setdiff(ls(), c('vessel.gps.dat', 'meta_dat_vessel', 'time.swim.dat.df',
                          'time.swim.meta.dat', 'time.swim.dat', 'samp_year', 'samp_year_folder',
                          'ts_meta_dat', 'ts.site.start.finish.loc', 'ts.sites.final.sf')))


```

```{r proposedsitejoin}
#| echo: false
#| warning: false
#| message: false


##---------------------------------------------------------------------------##
## 11. Join proposed site data to timed swim count data to identify sites sampled

# Load timed swim raw dataframe
time.swim.dat <- readRDS(paste(samp_year_folder, '/time.swim.dat.RDS', sep = ''))

# Load timed swim sites proposed dataframe
ts.sites.final.sf <- readRDS(paste(samp_year_folder, '/ts.sites.final.sf.RDS', sep = ''))
##---------------------------------------------------------------------------##
# Identify unique sites sampled from timed swim dataframe
ts.dat.unique <- time.swim.dat %>%
 distinct(site, sampyear, .keep_all = T) %>% 
 dplyr::select(c(site, sampyear, sampdate))
##---------------------------------------------------------------------------##
# Join sites sampled to renamed site file for 2020
ts.sites.join.2020 <- ts.sites.final.sf %>% 
 filter(sampyear == 2020) %>% 
 left_join(., ts.dat.unique, by = c('site_old' = 'site',
                                    'sampyear' = 'sampyear'))

# Join sites sampled to renamed site file for 2021
ts.sites.join.2021 <- ts.sites.final.sf %>% 
 filter(sampyear == 2021) %>% 
 left_join(., ts.dat.unique, by = c('site' = 'site',
                                    'sampyear' = 'sampyear'))

# Join sites sampled to renamed site file for 2022
ts.sites.join.2022 <- ts.sites.final.sf %>% 
 filter(sampyear == 2022) %>% 
 left_join(., ts.dat.unique, by = c('site' = 'site',
                                    'sampyear' = 'sampyear'))

# Join sites sampled to renamed site file for 2023
ts.sites.join.2023 <- ts.sites.final.sf %>% 
 filter(sampyear == 2023) %>% 
 left_join(., ts.dat.unique, by = c('site' = 'site',
                                    'sampyear' = 'sampyear'))

# Join sites sampled to renamed site file for 2024
ts.sites.join.2024 <- ts.sites.final.sf %>% 
 filter(sampyear == 2024) %>% 
 left_join(., ts.dat.unique, by = c('site' = 'site',
                                    'sampyear' = 'sampyear'))
##---------------------------------------------------------------------------##
# Compile joint site files
ts.dat.site.join <- bind_rows(ts.sites.join.2020, ts.sites.join.2021,
                              ts.sites.join.2022, ts.sites.join.2023,
                              ts.sites.join.2024)
##---------------------------------------------------------------------------##
# Identity sites sampled 
ts.dat.site.sampled <- ts.dat.site.join %>% 
 mutate(sampled = ifelse(is.na(sampdate), 0, 1)) %>%  
 dplyr::select(c(site, site_old, sampled, sampyear, geometry, oid))
##---------------------------------------------------------------------------##
# Transform to GDA2020
GDA2020 <- st_crs(7855)
ts.dat.site.sampled <- st_transform(ts.dat.site.sampled, GDA2020)
##---------------------------------------------------------------------------##
# read in Subblock map as an sf::sfc polygon object
sf.subblock.map <- st_read(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/GIS/SpatialLayers/SubBlockMaps.gpkg", Sys.info()[["user"]])))

# transform map to GDA2020
sf.subblock.map <- st_transform(sf.subblock.map, GDA2020)
##---------------------------------------------------------------------------##
# extract block number from site names
site.samp.loc <- ts.dat.site.sampled %>% 
 mutate(nums = str_count(site, '\\d+')) %>%
 mutate(site2 = ifelse(nums == 2, site, '')) %>% 
 separate(col = site2, into = c('ab', 'blockno'), sep = '-') %>% 
 mutate(site3 = ifelse(nums == 3, site, '')) %>% 
 separate(col = site3, into = c('ab', 'sampyear2', 'blockno2'), sep = '-') %>%
 mutate(blockno = ifelse(blockno %in% c(72, 74, 'LEG', 'THU'), 22, 
                         ifelse(blockno %in% c('BRS'), 13, blockno))) %>% 
 mutate(blockno = ifelse(is.na(blockno), blockno2, blockno)) %>% 
 dplyr::select(-c(ab, sampyear2, blockno2, nums))

##---------------------------------------------------------------------------##
# Join data to subblock map to identify subblockno and additional sites surveyed 

site.samp.subblock.loc <- st_join(site.samp.loc, sf.subblock.map, join = st_nearest_feature) %>% 
 dplyr::select(-c(version, area, blockno.y)) %>% 
 dplyr::rename(blockno = blockno.x) %>% 
 rename_all(tolower) %>% 
 mutate(subblockno = ifelse(subblockno == '29A' &
                             sampyear == 2020, '28C', 
                            ifelse(site == 'AB-23-50-A', '23A', subblockno))) %>%
 filter(
  (!subblockno %in% c('28C', '28B')) &
   (!blockno %in% c('14', '29', '30')) &
   (blockno != '13' | !sampyear %in% c(2021, 2022)))

##---------------------------------------------------------------------------##
# Join data to subblock map to identify subblockno (i.e. inc. all blocks)
site.samp.subblock.loc.ref <- st_join(site.samp.loc, sf.subblock.map, join = st_nearest_feature) %>% 
 dplyr::select(-c(version, area, blockno.y)) %>% 
 dplyr::rename(blockno = blockno.x) %>% 
 rename_all(tolower) %>% 
 mutate(subblockno = ifelse(subblockno == '29A' &
                             sampyear == 2020, '28C', 
                            ifelse(site == 'AB-23-50-A', '23A', subblockno)))

ts.proposed.geom <- site.samp.subblock.loc.ref
##---------------------------------------------------------------------------##
# Save file of actual geometry for raw data join
saveRDS(ts.proposed.geom, paste(samp_year_folder, '/ts.proposed.geom.RDS', sep = ''))

# save spatial layer for QGIS
st_write(ts.proposed.geom, 
         dsn = paste(samp_year_folder, '/ts.proposed.geom_', Sys.Date(), '.gpkg', sep = ''),
         layer = "ts.proposed.geom", driver = "GPKG", overwrite = T, delete_dsn = T)

rm(list = setdiff(ls(), c('vessel.gps.dat', 'meta_dat_vessel', 'time.swim.dat.df',
                          'time.swim.meta.dat', 'time.swim.dat', 'samp_year', 'samp_year_folder',
                          'ts_meta_dat', 'ts.site.start.finish.loc', 'ts.sites.final.sf',
                          'ts.proposed.geom')))

```


```{r actualsitejoin}
#| echo: false
#| warning: false
#| message: false


##---------------------------------------------------------------------------##
## 12. Join actual site data to timed swim count data 

## Create dataframe of actual sites sampled and generate map of sites sampled within 
## each Block with recorded GPS positions and 
## add subblock to site name based on vessel GPS data and start position
## use these data for 'actual geometry' when joining to raw data 

# load compiled vessel GPS data
vessel.gps.dat <- readRDS(paste(samp_year_folder, '/vessel.gps.dat.RDS', sep = ''))

# add sampdate
vessel.gps.dat <- vessel.gps.dat %>% 
 mutate(sampdate = as.Date(format(samptime, '%Y-%m-%d')))

# read in Subblock map as an sf::sfc polygon object
sf.subblock.map <- st_read(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/GIS/SpatialLayers/SubBlockMaps.gpkg", Sys.info()[["user"]])))

# transform map to GDA2020
GDA2020 <- st_crs(7855)
sf.subblock.map <- st_transform(sf.subblock.map, GDA2020)

# extract block number from site names
site.samp.start.loc <- vessel.gps.dat %>% 
        mutate(nums = str_count(site, '\\d+')) %>%
        mutate(site2 = ifelse(nums == 2, site, '')) %>%
        separate(col = site2, into = c('ab', 'blockno'), sep = '-') %>%
        mutate(site3 = ifelse(nums == 3, site, '')) %>%
        separate(col = site3, into = c('ab', 'sampyear2', 'blockno2'), sep = '-', remove = F) %>%
        mutate(blockno = ifelse(blockno %in% c(72, 74, 'LEG', 'THU'), 22, 
                                ifelse(blockno %in% c('BRS'), 13, blockno))) %>% 
        mutate(blockno = ifelse(is.na(blockno), blockno2, blockno)) %>%
        dplyr::select(-c(ab, sampyear2, blockno2, nums))

# join data to subblock map to identify subblockno and remove any blocks/sites 
# (i.e. these subblocks were open to fishing) and select start position
site.samp.start.subblock.loc <- st_join(site.samp.start.loc, sf.subblock.map, join = st_nearest_feature) %>% 
        dplyr::select(-c(version, area, blockno.y, site3)) %>% 
        dplyr::rename(blockno = blockno.x) %>% 
        rename_all(tolower) %>% 
        filter((!subblockno %in% c('28C', '28B') & sampperiod == 'start'))
                        # (!blockno %in% c('13', '14', '29', '30') & sampperiod == 'start'))

# join data to subblock map to identify subblockno and remove any blocks/sites 
# (i.e. these subblocks were open to fishing) and select finish position
site.samp.finish.subblock.loc <- st_join(site.samp.start.loc, sf.subblock.map, join = st_nearest_feature) %>% 
 dplyr::select(-c(version, area, blockno.y, site3)) %>% 
 dplyr::rename(blockno = blockno.x,
               finish.geom = geometry) %>% 
 rename_all(tolower) %>% 
 filter(
  (!subblockno %in% c('28C', '28B') & sampperiod == 'finish'))
   # (!blockno %in% c('13', '14', '29', '30') & sampperiod == 'finish'))

# adjust sub-block number where finish position of vessel has crept over block boundary
site.samp.finish.subblock.loc <- site.samp.finish.subblock.loc %>% 
 mutate(subblockno = case_when(site == 'AB-2024-23-7' & sampdate == as.Date('2024-07-23') ~ '23A', .default = subblockno))

# re-combine start and finish data
site.samp.start.finish <- left_join(as.data.frame(site.samp.start.subblock.loc), 
                as.data.frame(site.samp.finish.subblock.loc),
                by = c("sampyear", "sampdate", "site", 
                       "vesselname", "blockno", "zone",
                       "subblockno"))

# calculate straighline distance between start and finish position 
site.samp.distance <- site.samp.start.finish %>%
 mutate(dive_dist = units::drop_units(st_distance(geometry, finish.geom, by_element = T))) %>% 
 # mutate(distance = as.numeric(units::drop_units(st_distance(geometry, finish.geom, by_element = T)))) %>% 
 dplyr::rename(samptime = samptime.x,
               gpstime = gpstime.x,
               sampperiod = sampperiod.x,
               waypoint = waypoint.x) %>% 
 dplyr::select(-c(samptime.y, gpstime.y, sampperiod.y, waypoint.y, finish.geom)) 
 # st_as_sf()

 # calculate straightline direction between start and finish position
 site.samp.direction <- site.samp.start.finish %>%
 filter(!st_is_empty(geometry), !st_is_empty(finish.geom)) %>% 
 mutate(dive_dir = nngeo::st_azimuth(geometry, finish.geom)) %>%  
 dplyr::rename(samptime = samptime.x,
               gpstime = gpstime.x,
               sampperiod = sampperiod.x,
               waypoint = waypoint.x) %>% 
 dplyr::select(-c(samptime.y, gpstime.y, sampperiod.y, waypoint.y, finish.geom))
 # st_as_sf()

# rejoin straigline distance and direction tables 
 site_samp_dist_dir <- left_join(site.samp.distance, site.samp.direction) %>% 
  st_as_sf()

# join data to subblock map to identify subblockno (i.e. inc. all blocks)
site.samp.start.subblock.loc.ref <- st_join(site_samp_dist_dir, sf.subblock.map, join = st_nearest_feature) %>% 
 dplyr::select(-c(version, area, blockno.y, subblockno.y, zone.y)) %>% 
 dplyr::rename(blockno = blockno.x,
               subblockno = subblockno.x,
               zone = zone.x) %>% 
 rename_all(tolower) %>%  
 filter(sampperiod == 'start')

# load proposed site file
ts.sites.final.sf <- readRDS(paste(samp_year_folder, '/ts.sites.final.sf.RDS', sep = ''))

# join sites sampled to renamed site file for 2020
ts.actual.geom <- ts.sites.final.sf %>%
 st_drop_geometry() %>% 
 filter(sampyear == 2020) %>% 
 left_join(site.samp.start.subblock.loc.ref, ., by = c('site' = 'site_old',
                           'sampyear' = 'sampyear')) %>% 
 mutate(site_old = ifelse(sampyear == 2020, site, ''),
        site = ifelse(sampyear == 2020, site.y, site),
        site = ifelse(sampyear == 2020 & is.na(site), site_old, site)) %>%  
 dplyr::select(-site.y)

# save file of actual geometry for raw data join
saveRDS(ts.actual.geom, paste(samp_year_folder, '/ts.actual.geom.RDS', sep = ''))

# save spatial layer for QGIS
st_write(ts.actual.geom, 
         dsn = paste(samp_year_folder, '/ts.actual.geom_', Sys.Date(), '.gpkg', sep = ''),
         layer = "ts.actual.geom", driver = "GPKG", overwrite = T, delete_dsn = T)

rm(list = setdiff(ls(), c('vessel.gps.dat', 'meta_dat_vessel', 'time.swim.dat.df',
                          'time.swim.meta.dat', 'time.swim.dat', 'samp_year', 'samp_year_folder',
                          'ts_meta_dat', 'ts.site.start.finish.loc', 'ts.sites.final.sf',
                          'ts.proposed.geom', 'ts.actual.geom')))

```


```{r sitejoin}
#| echo: false
#| warning: false
#| message: false


##---------------------------------------------------------------------------##
## 12. Join site data ####
## Join spatial site data (proposed and actual GPS sites) to count and meta data

# Load raw count, proposed and actual site data frames
time.swim.dat <- readRDS(paste(samp_year_folder, '/time.swim.dat.RDS', sep = ''))
time.swim.dat.df <- readRDS(paste(samp_year_folder, '/time.swim.dat.df.RDS', sep = ''))
ts.actual.geom <- readRDS(paste(samp_year_folder, '/ts.actual.geom.RDS', sep = ''))
ts.proposed.geom <- readRDS(paste(samp_year_folder, '/ts.proposed.geom.RDS', sep = ''))

# add unique join ID
time.swim.dat <- time.swim.dat %>% 
        mutate(join_id = row_number())

# add sampdate to actual.geom file
ts.actual.geom <- ts.actual.geom %>% 
  mutate(sampdate = date(samptime))

# join proposed site data to size frequency data
        ts.dat.prop.2020 <- time.swim.dat %>% 
                filter(sampyear == 2020) %>% 
                left_join(., ts.proposed.geom, by = c('site' = 'site_old',
                                                   'sampyear' = 'sampyear')) %>%    
                mutate(site = ifelse(is.na(site.y), site, site.y)) 
        
        ts.dat.prop.2021 <- time.swim.dat %>% 
                filter(sampyear == 2021) %>% 
                left_join(., ts.proposed.geom, by = c('site' = 'site',
                                                      'sampyear' = 'sampyear'))
        ts.dat.prop.2022 <- time.swim.dat %>% 
         filter(sampyear == 2022) %>% 
         left_join(., ts.proposed.geom, by = c('site' = 'site',
                                               'sampyear' = 'sampyear'))
        
        ts.dat.prop.2023 <- time.swim.dat %>% 
         filter(sampyear == 2023) %>% 
         left_join(., ts.proposed.geom, by = c('site' = 'site',
                                               'sampyear' = 'sampyear'))
        
        ts.dat.prop.2024 <- time.swim.dat %>% 
         filter(sampyear == 2024) %>% 
         left_join(., ts.proposed.geom, by = c('site' = 'site',
                                               'sampyear' = 'sampyear'))
        
        ts.dat.prop <- bind_rows(ts.dat.prop.2020, ts.dat.prop.2021, 
                                 ts.dat.prop.2022, ts.dat.prop.2023,
                                 ts.dat.prop.2024) %>%   
                dplyr::select(-c(blockno.y, site.y, site_old)) %>% 
                dplyr::rename(proposed.geom = 'geometry',
                              blockno = 'blockno.x') 
        
# join actual site data to size frequency data
        ts.dat.act.2020 <- time.swim.dat %>% 
                filter(sampyear == 2020) %>%  
                left_join(., ts.actual.geom, by = c('site' = 'site_old',
                                                      'sampyear' = 'sampyear',
                                                    'sampdate')) %>%    
                mutate(site = ifelse(is.na(site.y), site, site.y)) %>% 
                dplyr::select(-site.y)
        
        ts.dat.act.2021 <- time.swim.dat %>% 
                filter(sampyear == 2021) %>% 
                left_join(., ts.actual.geom, by = c('site' = 'site',
                                                      'sampyear' = 'sampyear',
                                                    'sampdate'))
        
        ts.dat.act.2022 <- time.swim.dat %>% 
         filter(sampyear == 2022) %>% 
         left_join(., ts.actual.geom, by = c('site' = 'site',
                                             'sampyear' = 'sampyear',
                                             'sampdate'))
        
        ts.dat.act.2023 <- time.swim.dat %>% 
         filter(sampyear == 2023) %>% 
         left_join(., ts.actual.geom, by = c('site' = 'site',
                                             'sampyear' = 'sampyear',
                                             'sampdate'))
        
        ts.dat.act.2024 <- time.swim.dat %>% 
         filter(sampyear == 2024) %>% 
         left_join(., ts.actual.geom, by = c('site' = 'site',
                                             'sampyear' = 'sampyear',
                                             'sampdate'))
        
        ts.dat.act <- bind_rows(ts.dat.act.2020, ts.dat.act.2021, 
                                ts.dat.act.2022, ts.dat.act.2023,
                                ts.dat.act.2024) %>%    
                dplyr::select(-c(blockno.y, site_old)) %>% 
                dplyr::rename(actual.geom = 'geometry',
                              blockno = 'blockno.x')         
        
time.swim.dat.act.prop <- left_join(ts.dat.prop %>% dplyr::select(-c(subblockno, zone)), ts.dat.act %>% dplyr::select(-c(oid))) %>%  
        dplyr::select(c(site, sampdate, sampyear, blockno, subblockno, diver, starttime, 
                 firstabtime, finishtime, time.elapsed, sizeclass, sizeclass.2021, sizeclass_freq, 
                 minsize, midsize, midsize.2021, maxsize, legal.size, actual.geom, proposed.geom, dive_dist, dive_dir, oid))

# join proposed site data to individual length data

# add unique join ID
time.swim.dat.df <- time.swim.dat.df %>%
        mutate(join_id = row_number())

ts.dat.prop.df.2020 <- time.swim.dat.df %>%
        filter(sampyear == 2020) %>%
        left_join(., ts.proposed.geom, by = c('site' = 'site_old',
                                              'sampyear' = 'sampyear')) %>%
        mutate(site = ifelse(is.na(site.y), site, site.y))

ts.dat.prop.df.2021 <- time.swim.dat.df %>%
        filter(sampyear == 2021) %>%
        left_join(., ts.proposed.geom, by = c('site' = 'site',
                                              'sampyear' = 'sampyear'))

ts.dat.prop.df.2022 <- time.swim.dat.df %>%
 filter(sampyear == 2022) %>%
 left_join(., ts.proposed.geom, by = c('site' = 'site',
                                       'sampyear' = 'sampyear'))

ts.dat.prop.df.2023 <- time.swim.dat.df %>%
 filter(sampyear == 2023) %>%
 left_join(., ts.proposed.geom, by = c('site' = 'site',
                                       'sampyear' = 'sampyear'))

ts.dat.prop.df.2024 <- time.swim.dat.df %>%
 filter(sampyear == 2024) %>%
 left_join(., ts.proposed.geom, by = c('site' = 'site',
                                       'sampyear' = 'sampyear'))

ts.dat.prop.df <- bind_rows(ts.dat.prop.df.2020, ts.dat.prop.df.2021, 
                            ts.dat.prop.df.2022, ts.dat.prop.df.2023,
                            ts.dat.prop.df.2024) %>%
        dplyr::select(-c(blockno.y, site.y, site_old)) %>%
        dplyr::rename(proposed.geom = 'geometry',
                      blockno = 'blockno.x') %>%
        dplyr::select(c(-sampled))

# join actual site data to individual length data
ts.dat.act.df.2020 <- time.swim.dat.df %>%
        filter(sampyear == 2020) %>%
        left_join(., ts.actual.geom, by = c('site' = 'site_old',
                                            'sampyear' = 'sampyear',
                                            'sampdate')) %>%
        mutate(site = ifelse(is.na(site.y), site, site.y)) %>%
        dplyr::select(-site.y)

ts.dat.act.df.2021 <- time.swim.dat.df %>%
        filter(sampyear == 2021) %>%
        left_join(., ts.actual.geom, by = c('site' = 'site',
                                            'sampyear' = 'sampyear',
                                            'sampdate'))

ts.dat.act.df.2022 <- time.swim.dat.df %>%
 filter(sampyear == 2022) %>%
 left_join(., ts.actual.geom, by = c('site' = 'site',
                                     'sampyear' = 'sampyear',
                                     'sampdate'))

ts.dat.act.df.2023 <- time.swim.dat.df %>%
 filter(sampyear == 2023) %>%
 left_join(., ts.actual.geom, by = c('site' = 'site',
                                     'sampyear' = 'sampyear',
                                     'sampdate'))

ts.dat.act.df.2024 <- time.swim.dat.df %>%
 filter(sampyear == 2024) %>%
 left_join(., ts.actual.geom, by = c('site' = 'site',
                                     'sampyear' = 'sampyear',
                                     'sampdate'))

ts.dat.act.df <- bind_rows(ts.dat.act.df.2020, ts.dat.act.df.2021, 
                           ts.dat.act.df.2022, ts.dat.act.df.2023,
                           ts.dat.act.df.2024) %>%
        dplyr::select(-c(blockno.y, site_old)) %>%
        dplyr::rename(actual.geom = 'geometry',
                      blockno = 'blockno.x') %>%
        dplyr::select(-c(gpstime, sampperiod, samptime, waypoint))

time.swim.dat.df.act.prop <- left_join(ts.dat.prop.df %>% dplyr::select(-c(subblockno, zone)), ts.dat.act.df%>% dplyr::select(-c(oid))) %>%  
        dplyr::select(c(site, sampdate, sampyear, blockno, subblockno, diver, starttime,
                 firstabtime, finishtime, time.elapsed, shelllength, shelllength.2021, sizeclass, 
                 sizeclass.2021, sizeclass_freq, minsize, maxsize, legal.size, 
                 actual.geom, proposed.geom, dive_dist, dive_dir, oid))


time.swim.dat.final <- time.swim.dat.act.prop


time.swim.dat.df.final <- time.swim.dat.df.act.prop

```

```{r vesseljoin}
#| echo: false
#| warning: false
#| message: false


##---------------------------------------------------------------------------##
## 14. Join vessel GPS data to meta-data frame

# Import metadata frame
time.swim.meta.dat <- readRDS(paste(samp_year_folder, '/time.swim.meta.dat.RDS', sep = ''))

# Import vessel data frame
vessel.gps.dat <- readRDS(paste(samp_year_folder, '/vessel.gps.dat.RDS', sep = ''))

# remove leading zeros from waypoint numbers
vessel_gps_dat_zero <- vessel.gps.dat %>% 
 mutate(waypoint = as.numeric(gsub('^0+', '', waypoint)))

# rename variables in metadata 
ts_meta_dat_rename <- time.swim.meta.dat %>% 
 gather(., sampperiod, waypoint, waypoint.start:waypoint.finish) %>% 
 mutate(sampperiod = gsub('waypoint.', '', sampperiod),
        sampyear = year(sampdate)) %>% 
 dplyr::select(-c(sampdate))

# join meta and vessel data
ts_meta_dat_join <- ts_meta_dat_rename %>% 
 left_join(., vessel_gps_dat_zero)

# separate meta data start position and label
df_start <- ts_meta_dat_join %>% 
 filter(sampperiod == 'start') %>% 
 dplyr::rename(start_geom = 'geometry',
               start_gps_time = 'gpstime',
               start_waypoint = 'waypoint') %>% 
 dplyr::select(-c(sampperiod, finishtime))

# separate meta data finish position and label
df_finish <- ts_meta_dat_join %>% 
 filter(sampperiod == 'finish') %>% 
 dplyr::rename(finish_geom = 'geometry',
               finish_gps_time = 'gpstime',
               finish_waypoint = 'waypoint') %>% 
 dplyr::select(-c(sampperiod, starttime, samptime))

# rejoin start and finish data with labels
df_start_finish <- left_join(df_start, df_finish) %>% 
 dplyr::select(c(site, divers, starttime, finishtime, max.depth, habitat.type, percent.algae.cover,
          percent.urchins, urchin.deep, comments, vesselname, start_waypoint, finish_waypoint,
          start_gps_time, finish_gps_time, start_geom, finish_geom))

# extract block number from site names
time.swim.meta.dat.final <- df_start_finish %>% 
 mutate(nums = str_count(site, '\\d+')) %>% 
 # mutate(site2 = site) %>% 
 mutate(site2 = ifelse(nums == 2, site, '')) %>% 
 separate(col = site2, into = c('ab', 'blockno'), sep = '-') %>% 
 mutate(site3 = ifelse(nums == 3, site, '')) %>% 
 separate(col = site3, into = c('ab', 'sampyear2', 'blockno2'), sep = '-') %>%
 mutate(blockno = ifelse(blockno %in% c(72, 74, 'LEG', 'THU'), 22, 
                         ifelse(blockno %in% c('BRS'), 13, 
                                ifelse(blockno %in% c(2024), 29, blockno)))) %>% 
 mutate(blockno = ifelse(is.na(blockno), blockno2, blockno)) %>% 
 dplyr::select(-c(ab, sampyear2, blockno2, nums)) %>% 
 dplyr::select(c(site, blockno, divers, starttime, finishtime, max.depth, habitat.type, percent.algae.cover,
          percent.urchins, urchin.deep, comments, vesselname, start_waypoint, finish_waypoint,
          start_gps_time, finish_gps_time, start_geom, finish_geom))
```

```{r refsiteid}
#| echo: false
#| warning: false
#| message: false


##---------------------------------------------------------------------------##
## 15. Identify reference sites ####

# Import reference sites
time_swim_ref_sites <- readRDS(paste(sprintf("C:/Users/%s/Dropbox (UTAS Research)/shared/R_Stuff/FIS/FIS_2021/FIS_TimedSwimSurveys2021/time.swim.2020.repeat.sites.RDS", Sys.info()[["user"]])))

ref_sites <- time_swim_ref_sites %>%
 dplyr::select(site.new) %>%
 dplyr::rename(site = 'site.new') %>%
 mutate(ref_site = 1)

ts_dat_final_ref <- left_join(time.swim.dat.final, ref_sites, by = c('site'))
ts_dat_df_final_ref <- left_join(time.swim.dat.df.final, ref_sites, by = c('site'))
ts_meta_dat_final_ref <- left_join(time.swim.meta.dat.final, ref_sites, by = c('site'))

```

```{r finaldata}
#| echo: false
#| warning: false
#| message: false
##---------------------------------------------------------------------------##
# 16. Standardise data #### 

# Standardise counts for 10 minute swim (i.e. some swims marginally shorter or longer duration)
time.swim.dat.final <- ts_dat_final_ref %>% 
 mutate(sizeclass_freq_10 = round((sizeclass_freq / (time.elapsed) * 10)))

##---------------------------------------------------------------------------##
# 12. Rename column names ####

time_swim_dat_final <- time.swim.dat.final %>% 
 select_all(~gsub("\\s+|\\.", "_", .))

ts_dat_final_ref <-ts_dat_final_ref %>% 
 select_all(~gsub("\\s+|\\.", "_", .))

ts_dat_df_final_ref <- ts_dat_df_final_ref %>% 
 select_all(~gsub("\\s+|\\.", "_", .))

##---------------------------------------------------------------------------##
# 13. Save final dataframes ####

saveRDS(time_swim_dat_final, paste(samp_year_folder, '/time_swim_dat_final.RDS', sep = ''))
saveRDS(ts_dat_df_final_ref, paste(samp_year_folder, '/time_swim_dat_df_final.RDS', sep = ''))
saveRDS(ts_meta_dat_final_ref, paste(samp_year_folder, '/time_swim_meta_dat_final.RDS', sep = ''))
```