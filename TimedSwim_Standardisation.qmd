---
title: "Timed Swim Standardisation"
author:
  - name: Jaime McAllister
    affiliations:
        - name: IMAS, University of Tasmania
          department: IMAS-FA
date: last-modified
date-format: "[Last Updated on] DD MMMM, YYYY"
format:
  docx:
    highlight-style: github
    papersize: A4
    code-overflow: "wrap"
    reference-doc: word-styles-reference-01.docx
    toc: true
    number-sections: false
    toc-depth: 4
    number-depth: 4
    margin-left: 0.75in
    margin-right: 0.75in
    margin-top: 1in
    margin-bottom: 1in
    fig-format: png
    fig-dpi: 600
  pdf:
    documentclass: scrreport
    keep-tex:  true
    dpi: 600
    pdf-engine: lualatex
    toc: true
    toc-depth: 4
    toc_float: true
    number-sections: false
    number-depth: 4
    highlight-style: github
    papersize: "A4paper"
    linestretch: 1.25
    mainfont: Calibri
    geometry:
      - left = 20mm
      - right = 20mm
      - top = 20mm
      - bottom = 10mm
editor: 
  markdown: 
    wrap: 72
link-citations: true
---
\newpage

# Introduction

Timed swim surveys have been implemented as the primary method for fishery-independent assessment of abalone stocks. This approach is designed to evaluate the spatial extent of recovery and monitor progress toward established rebuilding benchmarks. The method provides rapid estimates of both abundance and population size structure across a large number of sites, offering practical advantages over more detailed transect-based techniques that require greater time and logistical effort.

Despite its efficiency, the timed swim method may be susceptible to observer bias, primarily due to differences in diver experience and search capacity, but also site variability and changing abundance of different size classes. Such biases can influence abundance estimates and compromise survey reliability. To mitigate these effects, standardisation procedures are applied that statistically account for individual diver performance, and site differences. In addition, the survey design in itself is aimed to minimise confounding between possible diver and site effects by ensuring multiple divers operate within each survey location and by limiting the total number of divers involved in the program.

This report presents the methodology used to standardise timed swim survey data, ensuring the resulting estimates of abalone abundance are reliable and resilient to biases arising from variation in diver performance.



```{r setup}
#| echo: false
#| warning: false
#| message: false

##---------------------------------------------------------------------------##
# clear console
rm(list = ls())

## 1. Load libraries ####
suppressPackageStartupMessages({
 library(dplyr)
 library(ggplot2)
 library(ggrepel)
 library(scales)
 library(tidyr)
 library(fs)
 library(gdata)
 library(openxlsx)
 library(lubridate)
 library(reshape)
 library(gridExtra)
 library(ggpubr)
 library(readxl)
 library(tibble)
 library(data.table)
 library(stringr)
 library(broom)
 library(purrr)
 library(sf)
 library(ggspatial)
 library(tmap)
  library(sp)
 library(RColorBrewer)
 library(viridis)
 library(ggpmisc)
 library(lme4)
 library(pbkrtest)
 library(AICcmodavg)
 library(visreg)
 library(glmmTMB)
 library(DHARMa)
 library(emmeans)
 library(ggeffects)
 library(ggExtra)
 # library(knitr)
})

source("C:/GitCode/AbResearch/getLegend.r")
source("C:/GitCode/AbResearch/StandardError_Functions.r")

```
# Load data

Load compiled length and metadata from survey outputs, including diver participation records. Exclude entries from AVG sampling conducted in 2024. Append 'enddate' timestamps for active divers to facilitate linkage with raw survey data.


```{r load data}
#| echo: false
#| warning: false
#| message: false

# Identify sampling year of interest
samp_year <- 2025

# Identify input and output folders
samp_year_folder <- file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/FISdata', 
                                            Sys.info()[["user"]])), paste('FIS_TimedSwimSurveys', samp_year, sep = ''))

ts_plots_folder <- file.path(paste(sprintf('C:/Users/%s/Dropbox (UTAS Research)/DiveFisheries/Abalone/Assessment/Figures/FIS', 
                                           Sys.info()[["user"]])), paste('FIS_TimedSwimSurveys', samp_year, '_Plots/Block_16_Re-opening_2024', sep = ''))

# Import final dataframes 
time_swim_dat_final <-
 readRDS(paste(samp_year_folder, '/time_swim_dat_final.RDS', sep = ''))

time_swim_dat_df_final <-
 readRDS(paste(samp_year_folder, '/time_swim_dat_df_final.RDS', sep = ''))

# Import metadata frame
time_swim_meta_dat_final <- readRDS(paste(samp_year_folder, '/time_swim_meta_dat_final.RDS', sep = ''))

# Import greenlip data (AIRF Project 2022/53)

# ts_dat_gl <- 

# Site filter for AVG sample collection in Block 28 on 2024-08-11
time_swim_dat_final <- time_swim_dat_final %>% 
 filter(sampdate != as.Date('2024-08-11') & site != 'AB-21-28-36',
        !site %in% c('DP1', 'DP2', 'DP3'))

time_swim_dat_df_final <- time_swim_dat_df_final %>% 
 filter(sampdate != as.Date('2024-08-11') & site != 'AB-21-28-36',
        !site %in% c('DP1', 'DP2', 'DP3'))

# Load diver details
time_swim_divers <- read.xlsx(paste(samp_year_folder, '/timed_swim_diver_details.xlsx', sep = ''), detectDates = T)

# Add end date for divers still participating
time_swim_divers <- time_swim_divers %>%
 mutate(end_date = if_else(is.na(end_date), Sys.Date(), end_date))

```
# Data preparation

Join diver participation records to raw survey data, excluding Joey M from 2021 entries to avoid misattribution due to name abbreviation overlap with Jaime M. Aggregate counts into total sub-legal and legal abundance per diver, block, and year. Filter out records from sub-blocks 28B and 28C surveyed in 2020 under the incorrect assumption that Block 28 was fully closed.

```{r data prepartion}
#| echo: false
#| warning: false
#| message: false

# Add unique diver_id to data
ts_dat <- fuzzyjoin::fuzzy_left_join(
  time_swim_dat_final, time_swim_divers,
  by = c("diver" = "diver", 
         "sampdate" = "start_date", 
         "sampdate" = "end_date"),
  match_fun = list(`==`, `>=`, `<=`)
) %>% 
 select(-c(diver.y, diver_name, diver_surname, dive_pair_id, dive_buddy_id, start_date, end_date)) %>% 
 dplyr::rename(diver = 'diver.x')

# Check diver_id for diver JM - Jaime M and Joey M but Jaime only dived in 2021 surveys
df_check <- ts_dat %>% 
 filter(diver == 'JM')

# Create site_year variable
ts_dat <- ts_dat %>% 
 mutate(site_year = paste(sampyear, site, sep = '_'),
        sampmonth = month(sampdate))

# Summarise counts by site, year, and diver
ts_working_dat <- ts_dat %>% 
 group_by(blockno, subblockno, site, site_year, sampyear, sampmonth, diver_id, legal_size) %>% 
 summarise(ab_n = sum(sizeclass_freq_10)) %>% 
 mutate(sampyear = factor(sampyear, levels = c(2020, 2021, 2022, 2023, 2024, 2025)),
        site = as.factor(site),
        diver_id = as.factor(diver_id),
        legal_size = as.factor(legal_size)) %>% 
 pivot_wider(
  names_from = legal_size,
  values_from = ab_n
 ) %>% 
 dplyr::rename(sublegal_n = '<140 mm',
               legal_n = '>140 mm') %>% 
 mutate(total_n = sublegal_n + legal_n,
        sublegal_prop = sublegal_n / total_n,
        legal_prop = legal_n / total_n)

# Exclude subblocks 28B and 28C from baseline data
# These were mistakenly surveyed under the assumption that Block 28 was entirely closed,
# but only subblock 28A was officially subject to closure.
ts_working_dat <- ts_working_dat %>% 
 filter(!subblockno %in% c('28B', '28C'))

# Split data into each block
ts_dat_working_list <- split(ts_working_dat, ts_working_dat$blockno, drop = TRUE)

# East coast block list for filtering
block_list <- c('16', '22', '23', '24', '27', '28')


```
# Data exploration

This preliminary analysis aims to critically examine the timed swim count dataset to uncover potential sources of bias that may influence observed patterns or trends. Through targeted visualisations and diagnostic assessments, we explore how spatial, temporal, and observational factors may distort or confound raw counts. The goal is to identify which covariates or structural elements warrant inclusion in a formal standardisation model to improve interpretability and comparability across surveys.

By isolating influential biases and assessing their effects, this step lays the groundwork for a robust modelling framework that enhances data reliability and supports more accurate ecological inference.

## Size structure bias

As legal abundance recovers across survey sites, there is growing concern that divers may be unintentionally shifting their attention toward aggregations of legal-sized individuals, spending more time counting them and inadvertently overlooking sublegal animals. This shift in survey focus can introduce bias into sublegal counts, potentially misrepresenting recruitment dynamics. Identifying and accounting for this observational bias is critical to ensure sublegal data remain a reliable indicator of population structure and ecological change.

```{r size bias}

size_summary <- ts_dat %>% 
 filter(blockno %in% block_list) %>% 
 group_by(blockno, subblockno, site, site_year, sampyear, diver_id, legal_size) %>% 
 summarise(ab_n = sum(sizeclass_freq_10)) %>% 
 mutate(sampyear = factor(sampyear, levels = c(2020, 2021, 2022, 2023, 2024, 2025)),
        site = as.factor(site),
        legal_size = as.factor(legal_size))

# Preview structure
glimpse(size_summary)

# Check counts by type
size_summary %>%
  group_by(sampyear, legal_size, blockno) %>%
  summarise(mean_count = mean(ab_n), sd_count = sd(ab_n), .groups = "drop")

# Density comparison
ggplot(size_summary, aes(x = ab_n, fill = legal_size)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~legal_size, scales = "free") +
  theme_minimal()

# Compare counts across type within the same grouping
paired_df <- size_summary %>%
  pivot_wider(names_from = legal_size, values_from = ab_n) %>% 
  dplyr::rename(sublegal_count = '<140 mm', 
                legal_count = '>140 mm') %>% 
  drop_na(sublegal_count, legal_count)

p <- ggplot(paired_df, aes(x = legal_count, y = sublegal_count)) +
  geom_point(alpha = 0.6) +
  # geom_smooth(method = "lm", se = TRUE, color = "blue") +
  theme_minimal()+
  facet_wrap(. ~ blockno)+
 facet_wrap(~blockno, scales = "free") +
  labs(
    title = "Sublegal vs Legal Counts",
    x = "Legal Count",
    y = "Sublegal Count"
  ) +
  theme_minimal(base_size = 14)

ggMarginal(p, type = "histogram")

plots <- lapply(unique(paired_df$blockno), function(b) {
  block_data <- subset(paired_df, blockno == b)
  base <- ggplot(block_data, aes(x = legal_count, y = sublegal_count)) +
    geom_point() +
    theme_minimal() +
    ggtitle(paste("Block", b))
  
  ggMarginal(base, type = "histogram")
})

# Arrange plots in a grid
grid.arrange(grobs = plots, ncol = 2)

plots

paired_df %>%
  filter(!is.na(legal_count), !is.na(sublegal_count)) %>%
  ggplot(aes(x = legal_count, y = sublegal_count)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", formula = y ~ x, color = "blue", se = TRUE) +
  facet_wrap(~blockno, scales = "free") +
  labs(
    title = "Sublegal vs Legal Counts with Linear Fit",
    x = "Legal Count",
    y = "Sublegal Count"
  ) +
  theme_minimal(base_size = 14)

paired_df %>%
  filter(!is.na(legal_count), !is.na(sublegal_count)) %>%
  ggplot(aes(x = legal_count, y = sublegal_count)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "darkorange", se = TRUE) +
  facet_wrap(~blockno, scales = "free") +
  labs(
    title = "Sublegal vs Legal Counts with Polynomial Fit",
    x = "Legal Count",
    y = "Sublegal Count"
  ) +
  theme_minimal(base_size = 14)


```

Across survey sites, sublegal and legal counts generally show a weak positive association, particularly at lower levels of legal abundance, where most observations are concentrated. However, this relationship is inconsistent across blocks and tends to degrade in many cases. Notably, when legal abundance reaches especially high levels, sublegal counts often decline, suggesting a potential non-linear pattern. This raises concerns that diver attention may become disproportionately focused on large aggregations of legal animals, leading to undercounting of sublegals. Such patterns indicate that factors beyond legal abundance may be shaping sublegal detections, warranting closer examination of observational bias and survey dynamics.

## Diver bias

Examination of bias between divers. Do we need to standardise for diver bias?

```{r diver bias}

diver_summary <- ts_dat %>% 
 filter(blockno %in% c(block_list)) %>%
 group_by(blockno, subblockno, site, site_year, sampyear, diver_id, legal_size) %>% 
 summarise(ab_n = sum(sizeclass_freq_10)) %>% 
 mutate(sampyear = factor(sampyear, levels = c(2020, 2021, 2022, 2023, 2024, 2025)),
        site = as.factor(site),
        diver_id = as.factor(diver_id),
        legal_size = as.factor(recode(legal_size,
                             "<140 mm" = "sublegal",
                             ">140 mm" = "legal")))

diver_summary %>%
  group_by(diver_id, sampyear) %>%
  summarise(dives = n_distinct(site), .groups = "drop")



model_diver <- glmmTMB(ab_n ~ legal_size * diver_id + (1 | site), 
                 family = nbinom2, data = diver_summary)

summary(model_diver)

# This negative binomial model (nbinom2 with a log link) quantifies sublegal abalone detections (<140 mm) across a spectrum of diver identities and site conditions, accounting for the presence or absence of legal-sized individuals (>140 mm). The fixed effects reveal systematic diver-based differences in detection under standard conditions, while interaction terms characterize how each diver's behavior shifts based on legal abundance. Sublegal counts were notably higher (∼2×) when legal abalone were absent (exp(0.70) ≈ 2.01), implying fewer visual distractions or more focused surveying. Diver-specific effects uncovered nuanced detection variability, with some individuals (e.g., ID13, ID14) consistently outperforming the baseline under legal presence, yet showing reduced counts when legal individuals were absent—potentially due to motivation or reliance on visual cues. Conversely, others (e.g., ID7, ID2) exhibited improved sublegal detection in the absence of legal abalone, possibly responding to lower search complexity. The model also highlighted site-level heterogeneity, with a random intercept variance of 0.53 (SD = 0.73), signaling considerable unexplained spatial variation across 1,251 locations. Overall, the findings emphasize that diver calibration and context-dependent behavior are critical in modeling sublegal abalone counts, and that integrating these effects substantially enhances ecological inference and survey reliability. robustness.


emmeans(model_diver, ~ diver_id | legal_size)  # Compare observers within each category

plot(emmeans(model_diver, ~ diver_id | legal_size))

#This double-panel plot visualizes estimated marginal means (emmeans) of sublegal abalone detections across diver IDs under two conditions: when legal-sized abalone are present and when only sublegal abalone are detected. The clear divergence in emmean values across panels highlights behavior-specific shifts by individual divers. Some consistently detect more sublegals when legal abalone are present, suggesting heightened responsiveness to multisize aggregations or more thorough surveying. Others show stronger sublegal detections when legal individuals are absent, possibly due to reduced visual clutter or shifts in effort. The comparison underscores that diver-specific patterns are context-dependent, reinforcing the model’s findings on interaction effects and the need for calibrating diver performance across sampling conditions

pairs(emmeans(model_diver, ~ diver_id | legal_size))

```

## Site variation

Is there variation in counts between sites?

```{r site variation}
#| echo: false
#| warning: false
#| message: false

site_summary <- ts_dat %>% 
 filter(blockno %in% block_list) %>% 
 group_by(blockno, subblockno, site, site_year, sampyear, legal_size) %>% 
 summarise(ab_n = sum(sizeclass_freq_10)) %>% 
 mutate(sampyear = factor(sampyear, levels = c(2020, 2021, 2022, 2023, 2024, 2025)),
        site = as.factor(site),
        legal_size = as.factor(recode(legal_size,
                             "<140 mm" = "sublegal",
                             ">140 mm" = "legal")))

# Plot counts by year
site_summary %>%
  filter(blockno %in% block_list) %>%
  ggplot(aes(x = sampyear, y = ab_n, color = legal_size)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.7) +
  theme_minimal() +
  facet_wrap(~ blockno) +
  labs(color = "Size",
       x = "Year",
       y = "Abalone Count")


```


# Model Development

## Survey Design

Timed swim surveys have been the primary method used to assess abalone abundance within closed fishing blocks in the Eastern Zone abalone fishery of Tasmania. The methodology has also been applied to areas currently open to fishing as part of long-term monitoring and experimental reliability assessments. In all cases, data are evaluated independently at the block level, though the core survey protocol remains consistent across regions.

Within the context of the Eastern Zone closure program, the survey framework includes:

- Blocks surveyed: Six blocks included in the assessment
- Temporal coverage: Annual sampling conducted from 2020 through 2025
- Site density: Approximately 60 sites per block each year
- Spatial distribution: Sites stratified across subblocks within each block
- Sampling structure:
 - 15 fixed (reference) sites revisited annually
 - 45 randomly selected sites surveyed each year
- Survey protocol:
 - At each site, two divers perform a 10-minute timed swim
 - All emergent abalone encountered are counted and measured
 - Abundance is partitioned into sub-legal and legal categories
 
## Analytical Objectives
Given the complexity of the survey design, standardisation is essential to account for methodological biases and variability in diver performance. Key analytical questions include:

- Is abalone abundance changing over time?
- Do certain subblocks exhibit consistently higher productivity?
- Do diver-specific effects influence count outcomes?
- Is there interdependence between legal and sub-legal abundance?

## Data Structure Overview

The resulting data exhibits the following structure:

- Response variable: Count data (sub-legal or legal abalone abundance)
- Predictor variable: Abundance of the alternate size class (e.g. legal vs. sub-legal)
- Spatial component: Sites nested within subblocks, with some sites repeatedly surveyed across years
- Temporal component: Annual variation with partially overlapping site-year combinations
- Replicates: Two diver observations per site-year

This structure defines a partially crossed, hierarchical design with potential for zero inflation due to low or zero counts in some observations.

## Modelling Framework

To accommodate the characteristics of the data, a Generalised Linear Mixed Model (GLMM) was implemented using the glmmTMB package in R. This approach offers flexibility to model:

- Overdispersed count responses using a Negative Binomial distribution
- Random effects for site and site-year variation
- Nested structure across diver replicates
- Potential zero inflation
- Ecological interactions between legal and sub-legal abundance

This framework supports robust inference while controlling for survey design complexities and observer heterogeneity.



# Create models

```{r model data}

block_dat <- ts_dat_working_list[["27"]]

```

## Model 1

Does the diver affect counts?

```{r model_1}
#| echo: false
#| warning: false
#| message: false


model_1 <- glmmTMB(sublegal_n ~ sampyear + (1|diver_id),
                 ziformula = ~1,
                 data = block_dat,
                 family = nbinom2)

VarCorr(model_1)
summary(model_1)

```

## Model 2

Does the diver and the abundance of legal/sub-legal abalone effect counts of the other?

A potential bias in the timed swim method is that counts of smaller or newly emerging abalone may be underestimated when larger, legal-sized individuals are more abundant. It’s thought that in such cases, observers may become disproportionately focused on scanning habitat suited to these larger individuals or may become occupied counting dense aggregations, reducing attention to other areas. Observers are instructed to search all available habitat and record all emergent abalone, defined as individuals visible without the need to move or disturb the surrounding habitat.

```{r model_2}
#| echo: false
#| warning: false
#| message: false


model_2 <- glmmTMB(sublegal_n ~ sampyear + legal_n + (1|diver_id),
                 ziformula = ~1,
                 data = block_dat,
                 family = nbinom2)

VarCorr(model_2)
summary(model_2)

```

## Model 3

Does site influence counts?

Some sites are repeated across years and others appear only once or intermittently. Therefore a partially crossed design rather than a fully nested or fully repeated-measures one.

- Site: Random effect because multiple sites exist and we are generalising beyond them.
- Year: Fixed effect as we are comparing known years directly.
- Site-year pairing: Some sites are repeated in years where some are unique.
- Legal abundance: sub-legal counts are potentially influenced by the abundance of legal abalone and potentially by temporal or site-level variability.
- Sub-legal/legal ratio: potentially consider a proportional factor of the total count (i.e. total count of sub-legal and legal and the proportion of the size category expressed in bin classes e.g. 0-10, 10-20, etc)

```{r model_3}
#| echo: false
#| warning: false
#| message: false


model_3 <- glmmTMB(sublegal_n ~ legal_n + sampyear + (1|diver_id) + (1|site) + (1|site:sampyear),
                 ziformula = ~1,
                 data = block_dat,
                 family = nbinom2)

VarCorr(model_3)
summary(model_3)

```

## Model 4

Without site as random effect.

Assumes: 

- Sites do no contribute meaningful variation
- Variation across years is modeled via a fixed effect
- All observations are pooled together regardless of site origin

If there’s site-level structure or clustering (e.g. some sites always have higher or lower abundance, or site-specific responses to predictors), dropping site as a random effect can:

- Underestimate standard errors (leading to false significance)
- Misrepresent uncertainty
- Flatten meaningful ecological variation

```{r model_4}
#| echo: false
#| warning: false
#| message: false


model_4 <- glmmTMB(sublegal_n ~ legal_n + sampyear + (1|diver_id),
                 ziformula = ~1,
                 data = block_dat,
                 family = nbinom2)

VarCorr(model_4)
summary(model_4)

```
## Model 5

An alternative that still treats sites as “grouped” but not randomly may be to split them into subblock?

```{r model_5}
#| echo: false
#| warning: false
#| message: false


model_5 <- glmmTMB(sublegal_n ~ legal_n + sampyear + subblockno + (1|diver_id),
                 ziformula = ~1,
                 data = block_dat,
                 family = nbinom2)

VarCorr(model_5)
summary(model_5)

```

## Model 6

Include subblockno to distinguish regionality in sites (i.e. are some areas of the block more productive than others?)

```{r model_6}
#| echo: false
#| warning: false
#| message: false


model_6 <- glmmTMB(sublegal_n ~ legal_n + sampyear + (1|diver_id) + (1|site) + (1 | subblockno) + (1|site:sampyear) ,
                 ziformula = ~1,
                 data = block_dat,
                 family = nbinom2)

VarCorr(model_6)
summary(model_6)

VarCorr(model_6)
summary(model_6)

```

# Compare and select model

Model 3 was selected as the preferred candidate for standardising timed swim survey data based on comparative AIC analysis. Its structure best accommodates the complexity of the survey design and ecological interactions underpinning abalone abundance. Overall, Model 3 offers a robust framework suited to hierarchical data with temporal, spatial, and ecological variability.

The response variable was sub-legal or legal abalone count. Explanatory variables and their treatment in the model were as follows:

- Site was included as a random effect to account for spatial heterogeneity across sampling locations and support generalisation beyond observed sites.
- Year was treated as a fixed effect, enabling direct comparison of temporal trends across known survey periods.
- Sub-legal or legal abundance was incorporated as a continuous covariate to assess potential density-dependent effects, under the assumption that counts of one size class may vary with the abundance of the other.
- Diver ID was included as an additional random effect to control for observer-specific variability in detection skill, and search behaviour. This helps mitigate bias arising from individual search patterns or preferential focus in dense aggregations of sub-legal or legal-sized abalone.

No explicit nesting of sites within years was applied, as several site-year pairings were unique. The model structure accommodates this variability and preserves flexibility in detecting cross-year patterns without imposing artificial constraints.

Model selection was guided by ecological rationale, goodness-of-fit criteria, and interpretability. All analyses were conducted using R (version 4.4.1), with significance assessed at α = 0.05.


```{r compare models}
#| echo: false
#| warning: false
#| message: false


models <- list(model_1, model_2, model_3, model_4, model_5, model_6)
mod_names <- c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5", "Model 6")

aictab(cand.set = models, modnames = mod_names)


```
## Run model

```{r block models}

# Identify unique blocks
block_list <- unique(ts_working_dat$blockno)
block_list <- setdiff(block_list, c("14", "30"))


# Define a function to fit models with swapped predictors
fit_models <- function(data, response_var, predictor_var) {
  glmmTMB(
    formula = as.formula(paste(response_var, "~", predictor_var, "+ sampyear + (1|diver_id) + (1|site) + (1|subblockno) + (1|site:sampyear)")),
    family = nbinom2(),
    ziformula = ~1,
    data = data
  )
}

# Loop through blocks and fit models
model_results <- map(block_list, function(i) {
  block_data <- ts_working_dat %>% filter(blockno == i)

  list(
    block = i,
    model_sublegal_resp = fit_models(block_data, "sublegal_n", "legal_n"),
    model_legal_resp    = fit_models(block_data, "legal_n", "sublegal_n")
  )
})

# Name the list
names(model_results) <- paste0("Block_", block_list)

```
## Model Diagnostics

```{r diagnostics}

map(model_results, ~ AIC(.x$model_sublegal_resp))
map(model_results, ~ AIC(.x$model_legal_resp))

map(model_results, ~ summary(.x$model_sublegal_resp)$coefficients$cond)
map(model_results, ~ summary(.x$model_legal_resp)$coefficients$cond)

model_summary <- tibble(
  block = map_chr(model_results, "block"),
  aic_sublegal = map_dbl(model_results, ~ AIC(.x$model_sublegal_resp)),
  aic_legal    = map_dbl(model_results, ~ AIC(.x$model_legal_resp))
)


# Simulate residuals for sublegal response models
res_sublegal <- map(model_results, ~ simulateResiduals(.x$model_sublegal_resp, n = 1000))

# Simulate residuals for legal response models
res_legal <- map(model_results, ~ simulateResiduals(.x$model_legal_resp, n = 1000))

walk2(res_sublegal, names(res_sublegal), ~ {
  plot(.x, main = paste("Residuals — Sublegal model", .y))
})

walk2(res_legal, names(res_legal), ~ {
  plot(.x, main = paste("Residuals — Legal model", .y))
})

diagnostics_legal <- map_dfr(names(res_legal), function(nm) {
  res <- res_legal[[nm]]
  tibble(
    Block = nm,
    Dispersion_p_legal = testDispersion(res)$p.value,
    ZeroInflation_p_legal = testZeroInflation(res)$p.value,
    Uniformity_p_legal = testUniformity(res)$p.value
  )
})

diagnostics_sublegal <- map_dfr(names(res_sublegal), function(nm) {
  res <- res_sublegal[[nm]]
  tibble(
    Block = nm,
    Dispersion_p_sublegal = testDispersion(res)$p.value,
    ZeroInflation_p_sublegal = testZeroInflation(res)$p.value,
    Uniformity_p_sublegal = testUniformity(res)$p.value
  )
})

diagnostic_comparison <- full_join(diagnostics_sublegal, diagnostics_legal, by = "Block")

diagnostic_flags <- diagnostic_comparison %>%
  mutate(across(
    starts_with("Dispersion_p"),
    ~ ifelse(. < 0.05, "⚠️", "✅"), .names = "disp_flag_{.col}"
  )) %>%
  mutate(across(
    starts_with("ZeroInflation_p"),
    ~ ifelse(. < 0.05, "⚠️", "✅"), .names = "zi_flag_{.col}"
  ))

knitr::kable(diagnostic_comparison, caption = "Residual Diagnostics for Legal and Sublegal GLMMs by Block")



```


$$
\begin{aligned}
\text{abundance}_{\text{sublegal},i} &= 
\underbrace{\beta_1 \cdot \text{abundance}_{\text{legal},i} + \beta_2 \cdot \text{fishyear}_i}_{\text{Fixed Effects}} \\
&\quad + \underbrace{u_{\text{diver}_i} + u_{\text{site}_i} + u_{\text{site:fishyear}_i}}_{\text{Random Effects}}
\end{aligned}
$$

# Standardise blacklip data

```{r data standardisation}
#| echo: false
#| warning: false
#| message: false


# Unique blocks
blocks <- unique(ts_working_dat$blockno)

# Containers
model_sublegal <- list()
model_legal <- list()
predictions <- list()

# # Check factor levels (need two or more for each factor)
# ts_working_dat %>%
#   group_by(blockno) %>%
#   summarise(
#     sampyear_levels = n_distinct(sampyear),
#     diver_levels = n_distinct(diver_id),
#     site_levels = n_distinct(site)
#   )


for (i in blocks) {
  # Filter data for each area
  dat_block <- ts_working_dat %>% filter(blockno == i)
  
  if (n_distinct(dat_block$sampyear) < 2) next  # Skip if only one year

  # === Model A: Sublegal ~ Legal ===
  sub_mod <- glmmTMB(
    sublegal_n ~ legal_n + sampyear +
      (1 | diver_id) + (1 | site) + (1 | subblockno) + (1 | sampmonth) + (1 | site:sampyear),
    ziformula = ~1,
    data = dat_block,
    family = nbinom2
  )

  # Predict sublegal abundance
  dat_block$sublegal_pred <- predict(sub_mod, newdata = dat_block, type = "response")

  # === Model B: Legal ~ Sublegal ===
  legal_mod <- glmmTMB(
    legal_n ~ sublegal_n + sampyear +
      (1 | diver_id) + (1 | site) + (1 | subblockno) + (1 | sampmonth) + (1 | site:sampyear),
    ziformula = ~1,
    data = dat_block,
    family = nbinom2
  )

  # Predict legal abundance
  dat_block$legal_pred <- predict(legal_mod, newdata = dat_block, type = "response")

  # Store models
  model_sublegal[[i]] <- sub_mod
  model_legal[[i]] <- legal_mod

  # Add block tag and store combined predictions
  dat_block$blockno <- i
  predictions[[i]] <- dat_block
}

# Combine all blocks into one master dataset
ts_pred_dat <- bind_rows(predictions)

# Make list
ts_pred_dat_list <- split(ts_pred_dat, ts_pred_dat$blockno, drop = TRUE)

```

# Standardise blacklip data - subblock

```{r data standardisation}
#| echo: false
#| warning: false
#| message: false


# Unique blocks
blocks <- unique(ts_working_dat$blockno)

# Containers
model_sublegal <- list()
model_legal <- list()
predictions <- list()

# # Check factor levels (need two or more for each factor)
# ts_working_dat %>%
#   group_by(blockno) %>%
#   summarise(
#     sampyear_levels = n_distinct(sampyear),
#     diver_levels = n_distinct(diver_id),
#     site_levels = n_distinct(site)
#   )


for (i in blocks) {
  # Filter data for each area
  dat_block <- ts_working_dat %>% filter(blockno == i)
  
  if (n_distinct(dat_block$sampyear) < 2) next  # Skip if only one year

  # === Model A: Sublegal ~ Legal ===
  sub_mod <- glmmTMB(
    sublegal_n ~ legal_n + sampyear +
      (1 | diver_id) + (1 | site) + (1 | sampmonth) + (1 | site:sampyear),
    ziformula = ~1,
    data = dat_block,
    family = nbinom2
  )

  # Predict sublegal abundance
  dat_block$sublegal_pred <- predict(sub_mod, newdata = dat_block, type = "response")

  # === Model B: Legal ~ Sublegal ===
  legal_mod <- glmmTMB(
    legal_n ~ sublegal_n + sampyear +
      (1 | diver_id) + (1 | site) + (1 | sampmonth) + (1 | site:sampyear),
    ziformula = ~1,
    data = dat_block,
    family = nbinom2
  )

  # Predict legal abundance
  dat_block$legal_pred <- predict(legal_mod, newdata = dat_block, type = "response")

  # Store models
  model_sublegal[[i]] <- sub_mod
  model_legal[[i]] <- legal_mod

  # Add block tag and store combined predictions
  dat_block$blockno <- i
  predictions[[i]] <- dat_block
}

# Combine all blocks into one master dataset
ts_pred_dat_subblock <- bind_rows(predictions)

# Make list
ts_pred_dat_list_subblock <- split(ts_pred_dat, ts_pred_dat$blockno, drop = TRUE)

```

```{r}

# Unique blocks
blocks_gl <- unique(ts_working_dat_gl$blockno)

# Containers
model_sublegal <- list()
model_legal <- list()
predictions <- list()

# # Check factor levels (need two or more for each factor)
# ts_working_dat_gl %>%
#   group_by(blockno) %>%
#   summarise(
#     sampyear_levels = n_distinct(sampyear),
#     diver_levels = n_distinct(diver_id),
#     site_levels = n_distinct(site)
#   )


for (i in blocks_gl) {
  # Filter data for each area
  dat_block <- ts_working_dat_gl %>% filter(blockno == i)
  
  if (n_distinct(dat_block$sampyear) < 2) next  # Skip if only one year

  # === Model A: Sublegal ~ Legal ===
  sub_mod <- glmmTMB(
    sublegal_n ~ legal_n + sampyear +
      (1 | diver_id) + (1 | site) + (1 | blockno) + (1 | site:sampyear),
    ziformula = ~1,
    data = dat_block,
    family = nbinom2
  )

  # Predict sublegal abundance
  dat_block$sublegal_pred <- predict(sub_mod, newdata = dat_block, type = "response")

  # === Model B: Legal ~ Sublegal ===
  legal_mod <- glmmTMB(
    legal_n ~ sublegal_n + sampyear +
      (1 | diver_id) + (1 | site) + (1 | blockno) + (1 | site:sampyear),
    ziformula = ~1,
    data = dat_block,
    family = nbinom2
  )

  # Predict legal abundance
  dat_block$legal_pred <- predict(legal_mod, newdata = dat_block, type = "response")

  # Store models
  model_sublegal[[i]] <- sub_mod
  model_legal[[i]] <- legal_mod

  # Add block tag and store combined predictions
  dat_block$blockno <- i
  predictions[[i]] <- dat_block
}

# Combine all blocks into one master dataset
ts_pred_dat_gl <- bind_rows(predictions)

# Make list
ts_pred_dat_list_gl <- split(ts_pred_dat_gl, ts_pred_dat_gl$blockno, drop = TRUE)

```

# Create archive file 

```{r writeoutput}
#| eval: true
#| echo: false
#| warning: false
#| message: false


Sys.time()
datetext <- now() |> format("%Y_%m_%d")

outfilename <- file.path(samp_year_folder, paste0("TimedSwimData_Stnd_", datetext, ".RData"))

save.image(file=outfilename)

```






